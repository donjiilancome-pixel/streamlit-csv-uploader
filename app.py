# app.py â€” Part 1/2
# -*- coding: utf-8 -*-
import io
import re
import sys
import math
import pytz
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta, time
import streamlit as st

# =========================
# åŸºæœ¬è¨­å®šãƒ»ã‚«ãƒ©ãƒ¼
# =========================
TZ = pytz.timezone("Asia/Tokyo")
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ¼ãƒ‰å¯è¦–åŒ–ã‚¢ãƒ—ãƒª", layout="wide")

# ç·šè‰²ï¼ˆã”è¦æœ›ã©ãŠã‚Šï¼‰
COLOR_VWAP = "#888888"   # ã‚°ãƒ¬ãƒ¼
COLOR_MA1  = "#2ca02c"   # ç·‘
COLOR_MA2  = "#ff7f0e"   # ã‚ªãƒ¬ãƒ³ã‚¸
COLOR_MA3  = "#1f77b4"   # é’

MAIN_CHART_HEIGHT  = 420
LARGE_CHART_HEIGHT = 620

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
@st.cache_data(show_spinner=False)
def try_read_csv(file, encodings=("utf-8-sig", "cp932", "shift_jis", "euc_jp")):
    last_err = None
    if hasattr(file, "read"):
        raw = file.read()
    else:
        raw = file
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception as e:
            last_err = e
            continue
    raise last_err

def to_numeric_jp(s):
    if s is None:
        return pd.Series(dtype=float)
    s = s.astype(str).str.replace(",", "", regex=False)\
                     .str.replace("\u3000", "", regex=False)\
                     .str.replace(" ", "", regex=False)\
                     .str.replace("âˆ’", "-", regex=False)\
                     .str.replace("ãƒ¼", "-", regex=False)
    s = s.str.extract(r"([-+]?\d+(?:\.\d+)?)", expand=False)
    return pd.to_numeric(s, errors="coerce")

def _to_jst_series(s, index):
    if s is None:
        return pd.Series(pd.NaT, index=index, dtype="datetime64[ns, Asia/Tokyo]")
    out = pd.to_datetime(s, errors="coerce", utc=False)
    if getattr(out.dt, "tz", None) is None:
        out = out.dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
    else:
        out = out.dt.tz_convert(TZ)
    return out

def pick_dt_col(df: pd.DataFrame):
    """æ—¥ä»˜/æ—¥æ™‚ã£ã½ã„åˆ—å€™è£œã‹ã‚‰æœ€åˆã‚’è¿”ã™"""
    if df is None or df.empty:
        return None
    cand = [c for c in df.columns if any(k in str(c) for k in ["ç´„å®šæ—¥", "ç´„å®šæ—¥æ™‚", "æ—¥æ™‚", "æ—¥ä»˜", "ç´„å®šæ™‚é–“", "time", "date", "Date"])]
    return cand[0] if cand else None

def pick_dt_with_optional_time(df: pd.DataFrame):
    """
    df å†…ã®ã€Œç´„å®šæ—¥ + (ç´„å®šæ™‚é–“|æ™‚åˆ»)ã€ or ã€Œç´„å®šæ—¥æ™‚ã€ã‹ã‚‰ JST ã® Timestamp ã‚’ä½œã‚‹ã€‚
    """
    if df is None or df.empty:
        return pd.Series(pd.NaT, index=df.index)
    cols = list(df.columns)
    # å…ˆã«ã€Œç´„å®šæ—¥æ™‚ã€ç³»ã‚’è©¦ã™
    dtcol = None
    for k in ["ç´„å®šæ—¥æ™‚", "æ—¥æ™‚", "time", "Time", "ç´„å®šæ™‚åˆ»", "ExecutionTime", "å–å¼•æ™‚é–“"]:
        if k in cols:
            dtcol = k; break
    if dtcol:
        s = pd.to_datetime(df[dtcol], errors="coerce")
        if getattr(s.dt, "tz", None) is None:
            s = s.dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
        else:
            s = s.dt.tz_convert(TZ)
        return s

    # ã€Œç´„å®šæ—¥ + ç´„å®šæ™‚é–“/æ™‚åˆ»ã€ ã‚’çµåˆ
    dcol = None
    for k in ["ç´„å®šæ—¥", "æ—¥ä»˜", "Date"]:
        if k in cols:
            dcol = k; break
    tcol = None
    for k in ["ç´„å®šæ™‚é–“", "æ™‚åˆ»", "Time", "ç´„å®šæ™‚åˆ»"]:
        if k in cols:
            tcol = k; break
    if dcol and tcol:
        ds = pd.to_datetime(df[dcol], errors="coerce").dt.date.astype(str)
        ts = df[tcol].astype(str).str.replace(r"[^\d:]", "", regex=True)
        s = pd.to_datetime(ds + " " + ts, errors="coerce")
        s = s.dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
        return s

    # æœ€å¾Œã®ç ¦ï¼šæ—¥ä»˜ã ã‘
    if dcol:
        s = pd.to_datetime(df[dcol], errors="coerce")
        s = s.dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
        return s
    return pd.Series(pd.NaT, index=df.index)

def extract_code_from_ohlc_key(key: str):
    """'TSE_9984, 3_xxxx.csv' ãªã©ã‹ã‚‰ 4æ¡ã‚³ãƒ¼ãƒ‰ã‚’æ¨å®š"""
    if not key:
        return None
    m = re.search(r"(\d{4})", key)
    return m.group(1) if m else None

def ohlc_global_date_range(ohlc_map: dict):
    tmin, tmax = None, None
    for _, df in ohlc_map.items():
        if df is None or df.empty or "time" not in df.columns:
            continue
        tt = _to_jst_series(df["time"], df.index)
        mn, mx = tt.min(), tt.max()
        if pd.isna(mn) or pd.isna(mx):
            continue
        if tmin is None or mn < tmin: tmin = mn
        if tmax is None or mx > tmax: tmax = mx
    if tmin is None: return None, None
    return tmin.date(), tmax.date()

def download_button_df(df: pd.DataFrame, label: str, filename: str):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(label=label, data=csv, file_name=filename, mime="text/csv")

# ===== æ•°å€¤ã‚½ãƒ¼ãƒˆã‚’ç¢ºå®Ÿã«ã™ã‚‹å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆæ–°è¦ â‘ â‘¡â‘¢ï¼‰ =====
def _coerce_numeric_jp(val):
    """
    '90,077' ã‚„ 'âˆ’5,310'(U+2212) / '(1,234)' / ç©ºç™½ ãªã©ã‚’æ•°å€¤ã¸ã€‚å¤±æ•—æ™‚ NaNã€‚
    """
    if pd.isna(val):
        return np.nan
    s = str(val).strip()
    if s == "":
        return np.nan
    neg = False
    if s.startswith("(") and s.endswith(")"):
        neg = True
        s = s[1:-1]
    s = s.replace(",", "").replace("\u3000", "").replace(" ", "")
    trans = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼", "0123456789-")
    s = s.translate(trans).replace("âˆ’", "-").replace("ãƒ¼", "-")
    m = re.search(r"[-+]?\d+(\.\d+)?", s)
    if not m:
        return np.nan
    x = float(m.group(0))
    if neg:
        x = -x
    return x

def _numify_cols(df: pd.DataFrame, cols: list[str], round0=False) -> pd.DataFrame:
    df = df.copy()
    for c in cols:
        if c in df.columns:
            df[c] = df[c].map(_coerce_numeric_jp)
            if round0:
                df[c] = pd.to_numeric(df[c], errors="coerce").round(0)
    return df

def show_numeric_table(df: pd.DataFrame, num_formats: dict[str, str], index=False, key=None):
    cfg = {}
    for col, fmt in num_formats.items():
        if col in df.columns:
            cfg[col] = st.column_config.NumberColumn(col, format=fmt)
    st.dataframe(df, use_container_width=True, hide_index=not index, column_config=cfg, key=key)

# =========================
# ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
# =========================
st.sidebar.header("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
up_realized = st.sidebar.file_uploader("å®Ÿç¾æç›Šï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)
up_yakujyou = st.sidebar.file_uploader("ç´„å®šå±¥æ­´ï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)
up_ohlc     = st.sidebar.file_uploader("3åˆ†è¶³OHLCï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)

# =========================
# å®Ÿç¾æç›Šãƒ»ç´„å®šå±¥æ­´ã®æ­£è¦åŒ–
# =========================
@st.cache_data(show_spinner=False)
def normalize_realized(files):
    if not files:
        return pd.DataFrame()
    dfs = []
    for f in files:
        try:
            df = try_read_csv(f)
            df["__src__"] = getattr(f, "name", "uploaded.csv")
            dfs.append(df)
        except Exception as e:
            st.warning(f"å®Ÿç¾æç›Šã®èª­è¾¼å¤±æ•—: {getattr(f,'name','(unknown)')} / {e}")
    if not dfs:
        return pd.DataFrame()
    d = pd.concat(dfs, ignore_index=True)

    # é‡‘é¡åˆ—ã®æ¨å®š
    pl_col = None
    cand = ["å®Ÿç¾æç›Š", "å®Ÿç¾æç›Š[å††]", "æç›Š", "æç›Šï¼ˆå††ï¼‰", "RealizedPnL", "PL", "profit", "é‡‘é¡"]
    for c in d.columns:
        if any(k in str(c) for k in cand):
            pl_col = c; break
    if pl_col is None:
        # ã©ã†ã—ã¦ã‚‚ç„¡ã„å ´åˆã¯ã‚¼ãƒ­
        d["pl"] = 0.0
    else:
        d["pl"] = to_numeric_jp(d[pl_col])

    # éŠ˜æŸ„åãƒ»ã‚³ãƒ¼ãƒ‰å€™è£œ
    name_col = next((c for c in d.columns if any(k in str(c) for k in ["éŠ˜æŸ„å", "åç§°", "Name"])), None)
    code_col = next((c for c in d.columns if any(k in str(c) for k in ["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰", "ã‚³ãƒ¼ãƒ‰", "Symbol", "Code"])), None)
    if code_col: d["code_key"] = d[code_col].astype(str).str.extract(r"(\d{4})", expand=False)
    if name_col: d["name_key"] = d[name_col].astype(str)

    # æ—¥æ™‚
    d["ç´„å®šæ—¥æ™‚_final"] = pick_dt_with_optional_time(d)
    d["ç´„å®šæ—¥_final"]   = pd.to_datetime(d["ç´„å®šæ—¥æ™‚_final"], errors="coerce").dt.tz_convert(TZ).dt.date

    return d

@st.cache_data(show_spinner=False)
def normalize_yakujyou(files):
    if not files:
        return pd.DataFrame()
    dfs = []
    for f in files:
        try:
            df = try_read_csv(f)
            df["__src__"] = getattr(f, "name", "uploaded.csv")
            dfs.append(df)
        except Exception as e:
            st.warning(f"ç´„å®šå±¥æ­´ã®èª­è¾¼å¤±æ•—: {getattr(f,'name','(unknown)')} / {e}")
    if not dfs:
        return pd.DataFrame()
    d = pd.concat(dfs, ignore_index=True)

    code_col = next((c for c in d.columns if any(k in str(c) for k in ["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰", "ã‚³ãƒ¼ãƒ‰", "Symbol", "Code"])), None)
    name_col = next((c for c in d.columns if any(k in str(c) for k in ["éŠ˜æŸ„å", "åç§°", "Name"])), None)
    if code_col: d["code_key"] = d[code_col].astype(str).str.extract(r"(\d{4})", expand=False)
    if name_col: d["name_key"] = d[name_col].astype(str)

    d["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(d)
    d["ç´„å®šæ—¥"]   = pd.to_datetime(d["ç´„å®šæ—¥æ™‚"], errors="coerce").dt.tz_convert(TZ).dt.date
    return d

@st.cache_data(show_spinner=False)
def normalize_ohlc(files):
    """
    æœŸå¾…åˆ—: time, open, high, low, close[, volume][, VWAP][, MA1][, MA2][, MA3]
    """
    if not files:
        return {}
    out = {}
    for f in files:
        try:
            df = try_read_csv(f)
            # åˆ—åã‚†ã‚‰ãå¯¾å¿œ
            cols = {c.lower(): c for c in df.columns}
            def pick(*cand):
                for k in cand:
                    if k in cols: return cols[k]
                return None
            tcol = pick("time", "æ—¥æ™‚", "date", "datetime")
            ocol = pick("open", "å§‹å€¤")
            hcol = pick("high", "é«˜å€¤")
            lcol = pick("low",  "å®‰å€¤")
            ccol = pick("close","çµ‚å€¤","close_price")

            if not all([tcol, ocol, hcol, lcol, ccol]):
                st.warning(f"OHLCåˆ—ãŒä¸è¶³: {getattr(f,'name','file')}")
                continue
            d = pd.DataFrame({
                "time": pd.to_datetime(df[tcol], errors="coerce"),
                "open": to_numeric_jp(df[ocol]),
                "high": to_numeric_jp(df[hcol]),
                "low":  to_numeric_jp(df[lcol]),
                "close":to_numeric_jp(df[ccol]),
            })
            # æ—¢ã« tz ä»˜ãã§ãªã‘ã‚Œã° JST ã‚’ä»˜ä¸
            if getattr(d["time"].dt, "tz", None) is None:
                d["time"] = d["time"].dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
            else:
                d["time"] = d["time"].dt.tz_convert(TZ)

            # è¿½åŠ åˆ—ï¼ˆä»»æ„ï¼‰
            for k in ["volume", "VWAP", "MA1", "MA2", "MA3"]:
                col = pick(k.lower(), k)
                if col and col in df.columns:
                    d[k] = to_numeric_jp(df[col])
            key = getattr(f, "name", f"ohlc_{len(out)+1}.csv")
            out[key] = d.dropna(subset=["time"]).sort_values("time")
        except Exception as e:
            st.warning(f"OHLCã®èª­è¾¼å¤±æ•—: {getattr(f,'name','(unknown)')} / {e}")
    return out

realized_all = normalize_realized(up_realized)
yakujyou_all = normalize_yakujyou(up_yakujyou)
ohlc_map     = normalize_ohlc(up_ohlc)

# éŠ˜æŸ„åè¾æ›¸ï¼ˆ3åˆ†è¶³ã®æƒ³å®šåã«ã‚‚ä½¿ç”¨ï¼‰
CODE_TO_NAME = {}
if not realized_all.empty and "code_key" in realized_all.columns and "name_key" in realized_all.columns:
    s = realized_all.dropna(subset=["code_key","name_key"]).drop_duplicates("code_key")[["code_key","name_key"]]
    CODE_TO_NAME.update(dict(zip(s["code_key"].str.upper(), s["name_key"])))
if not yakujyou_all.empty and "code_key" in yakujyou_all.columns and "name_key" in yakujyou_all.columns:
    s = yakujyou_all.dropna(subset=["code_key","name_key"]).drop_duplicates("code_key")[["code_key","name_key"]]
    CODE_TO_NAME.update(dict(zip(s["code_key"].str.upper(), s["name_key"])))

st.title("ğŸ“ˆ æŠ•è³‡ç®¡ç†ã‚¢ãƒ—ãƒªï¼ˆStreamlitï¼‰")

# =========================
# 1) é›†è¨ˆï¼ˆæœŸé–“åˆ¥ï¼‰
# =========================
tab1, tab2, tab3, tab4, tab5 = st.tabs(["é›†è¨ˆï¼ˆæœŸé–“åˆ¥ï¼‰","é›†è¨ˆï¼ˆæ™‚é–“åˆ¥ï¼‰","ç´¯è¨ˆæç›Š","å€‹åˆ¥/ãƒ©ãƒ³ã‚­ãƒ³ã‚°","3åˆ†è¶³ IN/OUT + æŒ‡æ¨™"])

with tab1:
    st.subheader("å®Ÿç¾æç›Šï¼ˆæœŸé–“åˆ¥é›†è¨ˆï¼‰")
    if realized_all.empty:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        d = realized_all.copy()
        # æ—¥åˆ¥
        day = d.groupby("ç´„å®šæ—¥_final", dropna=True)["pl"].sum().reset_index().rename(columns={"ç´„å®šæ—¥_final":"æ—¥ä»˜", "pl":"å®Ÿç¾æç›Š[å††]"})
        day = day.sort_values("æ—¥ä»˜")
        day = _numify_cols(day, ["å®Ÿç¾æç›Š[å††]"], round0=True)
        st.markdown("**æ—¥åˆ¥**")
        show_numeric_table(day, {"å®Ÿç¾æç›Š[å††]":"%,.0f"}, key="period_day")
        # é€±åˆ¥
        d["week"] = pd.to_datetime(d["ç´„å®šæ—¥_final"]).astype("datetime64[ns]")
        wk = d.dropna(subset=["week"]).copy()
        wk["week"] = wk["week"].dt.to_period("W").apply(lambda p: p.start_time.date())
        week = wk.groupby("week")["pl"].sum().reset_index().rename(columns={"week":"é€±", "pl":"å®Ÿç¾æç›Š[å††]"})
        week = week.sort_values("é€±")
        week = _numify_cols(week, ["å®Ÿç¾æç›Š[å††]"], round0=True)
        st.markdown("**é€±åˆ¥**")
        show_numeric_table(week, {"å®Ÿç¾æç›Š[å††]":"%,.0f"}, key="period_week")
        # æœˆåˆ¥
        mo = d.copy()
        mo["month"] = pd.to_datetime(mo["ç´„å®šæ—¥_final"]).astype("datetime64[ns]")
        mo = mo.dropna(subset=["month"])
        mo["month"] = mo["month"].dt.to_period("M").apply(lambda p: p.start_time.date())
        month = mo.groupby("month")["pl"].sum().reset_index().rename(columns={"month":"æœˆ", "pl":"å®Ÿç¾æç›Š[å††]"})
        month = month.sort_values("æœˆ")
        month = _numify_cols(month, ["å®Ÿç¾æç›Š[å††]"], round0=True)
        st.markdown("**æœˆåˆ¥**")
        show_numeric_table(month, {"å®Ÿç¾æç›Š[å††]":"%,.0f"}, key="period_month")

        # ç·šã‚°ãƒ©ãƒ•ï¼ˆæ—¥åˆ¥ï¼‰
        if not day.empty:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=pd.to_datetime(day["æ—¥ä»˜"]), y=day["å®Ÿç¾æç›Š[å††]"], mode="lines+markers", name="æ—¥åˆ¥PL"))
            fig.update_layout(
                height=360, xaxis_rangeslider_visible=False,
                xaxis=dict(type="date", tickformat="%Y-%m-%d"),
                yaxis=dict(tickformat=",.0f"),
                margin=dict(l=10,r=10,t=10,b=10)
            )
            st.plotly_chart(fig, use_container_width=True)

# =========================
# 2) é›†è¨ˆï¼ˆæ™‚é–“åˆ¥ï¼‰
# =========================
with tab2:
    st.subheader("å®Ÿç¾æç›Šï¼ˆæ™‚é–“åˆ¥ãƒ»1æ™‚é–“ã”ã¨ï¼‰")
    if realized_all.empty and yakujyou_all.empty:
        st.info("å®Ÿç¾æç›Šã¾ãŸã¯ç´„å®šå±¥æ­´ãŒå¿…è¦ã§ã™ã€‚")
    else:
        # æ™‚é–“æƒ…å ±ã¯ realized ã«ã‚ã‚Œã°æœ€å„ªå…ˆã€ç„¡ã‘ã‚Œã° yakujyou
        if not realized_all.empty and realized_all["ç´„å®šæ—¥æ™‚_final"].notna().any():
            dt = realized_all[["ç´„å®šæ—¥æ™‚_final","pl"]].dropna()
            dt_col = "ç´„å®šæ—¥æ™‚_final"
            pl_col = "pl"
        elif not yakujyou_all.empty and yakujyou_all["ç´„å®šæ—¥æ™‚"].notna().any():
            # yak ã«ã¯æç›ŠãŒç„¡ã„ã“ã¨ãŒå¤šã„ã®ã§é‡‘é¡ã¯ã‚«ã‚¦ãƒ³ãƒˆã®ã¿ã«ãªã‚‹å ´åˆã‚ã‚Š
            dt = yakujyou_all[["ç´„å®šæ—¥æ™‚"]].dropna().copy()
            dt["pl"] = 0.0
            dt_col = "ç´„å®šæ—¥æ™‚"
            pl_col = "pl"
        else:
            st.info("å¸‚å ´æ™‚é–“å†…ã«â€œæ™‚åˆ»ä»˜ãâ€ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            dt = pd.DataFrame()

        if not dt.empty:
            tt = pd.to_datetime(dt[dt_col], errors="coerce")
            if getattr(tt.dt, "tz", None) is None:
                tt = tt.dt.tz_localize(TZ, nonexistent="NaT", ambiguous="NaT")
            else:
                tt = tt.dt.tz_convert(TZ)
            dt = dt.assign(__t__=tt).dropna(subset=["__t__"])
            tl = dt["__t__"].dt.time
            mask_mkt = (tl >= time(9,0)) & (tl <= time(15,30))
            dt = dt[mask_mkt]
            if dt.empty:
                st.info("å¸‚å ´æ™‚é–“å†…ã®æ™‚åˆ»ä»˜ããƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                dt["hour"] = dt["__t__"].dt.floor("h").dt.strftime("%H:00")
                g = dt.groupby("hour").agg(åæ”¯=(pl_col,"sum"),
                                          å–å¼•å›æ•°=(pl_col,"count"),
                                          å¹³å‡æç›Š=(pl_col,"mean")).reset_index()
                # å‹ç‡ï¼ˆpl>0ã®æ¯”ç‡ï¼‰
                win = dt.assign(win=(dt[pl_col] > 0).astype(int)).groupby(dt["__t__"].dt.floor("h")).agg(win=("win","mean")).reset_index()
                win["hour"] = win["__t__"].dt.strftime("%H:00")
                g = g.merge(win[["hour","win"]], on="hour", how="left").rename(columns={"win":"å‹ç‡"})
                g = g.sort_values("hour")

                # æ•°å€¤åŒ–ï¼†è¡¨ç¤ºï¼ˆã‚«ãƒ³ãƒæ›¸å¼ãƒ»æ•°å€¤ã‚½ãƒ¼ãƒˆå¯ï¼‰
                g = _numify_cols(g, ["åæ”¯","å¹³å‡æç›Š","å‹ç‡","å–å¼•å›æ•°"], round0=False)
                # å‹ç‡(0-1)â†’%
                if g["å‹ç‡"].notna().any(): g["å‹ç‡"] = g["å‹ç‡"]*100.0
                show_numeric_table(g, {"åæ”¯":"%,.0f", "å¹³å‡æç›Š":"%,.0f", "å‹ç‡":"%.1f%%", "å–å¼•å›æ•°":"%,d"}, key="by_hour")

                # åæ”¯/å‹ç‡ã®ç·šã‚°ãƒ©ãƒ•
                if not g.empty:
                    x = g["hour"]
                    fig = go.Figure()
                    fig.add_trace(go.Bar(x=x, y=g["å–å¼•å›æ•°"], name="å–å¼•å›æ•°", yaxis="y2", opacity=0.3))
                    fig.add_trace(go.Scatter(x=x, y=g["åæ”¯"], name="åæ”¯", mode="lines+markers"))
                    fig.add_trace(go.Scatter(x=x, y=g["å‹ç‡"], name="å‹ç‡(%)", mode="lines+markers", yaxis="y3"))
                    fig.update_layout(
                        height=360, xaxis=dict(type="category"),
                        yaxis=dict(title="åæ”¯", tickformat=",.0f"),
                        yaxis2=dict(title="å›æ•°", overlaying="y", side="right", showgrid=False),
                        yaxis3=dict(title="å‹ç‡(%)", overlaying="y", anchor="free", position=1.08, showgrid=False),
                        legend=dict(orientation="h"), margin=dict(l=10,r=60,t=10,b=10)
                    )
                    st.plotly_chart(fig, use_container_width=True)

# app.py â€” Part 2/2

# =========================
# 3) ç´¯è¨ˆæç›Š
# =========================
with tab3:
    st.subheader("ç´¯è¨ˆæç›Š")
    if realized_all.empty:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        d = realized_all.copy()
        day = d.groupby("ç´„å®šæ—¥_final", dropna=True)["pl"].sum().reset_index().rename(columns={"ç´„å®šæ—¥_final":"æ—¥ä»˜", "pl":"å®Ÿç¾æç›Š[å††]"})
        day = day.sort_values("æ—¥ä»˜")
        day["ç´¯è¨ˆ"] = day["å®Ÿç¾æç›Š[å††]"].cumsum()
        day = _numify_cols(day, ["å®Ÿç¾æç›Š[å††]","ç´¯è¨ˆ"], round0=True)

        show_numeric_table(day, {"å®Ÿç¾æç›Š[å††]":"%,.0f", "ç´¯è¨ˆ":"%,.0f"}, key="cum_table")

        if not day.empty:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=pd.to_datetime(day["æ—¥ä»˜"]), y=day["å®Ÿç¾æç›Š[å††]"], name="æ—¥æ¬¡PL"))
            fig.add_trace(go.Scatter(x=pd.to_datetime(day["æ—¥ä»˜"]), y=day["ç´¯è¨ˆ"], name="ç´¯è¨ˆ", mode="lines"))
            fig.update_layout(
                height=380, xaxis_rangeslider_visible=False,
                xaxis=dict(type="date", tickformat="%Y-%m-%d"),
                yaxis=dict(tickformat=",.0f"),
                margin=dict(l=10,r=10,t=10,b=10)
            )
            st.plotly_chart(fig, use_container_width=True)

# =========================
# 4) å€‹åˆ¥/ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# =========================
with tab4:
    st.subheader("å€‹åˆ¥éŠ˜æŸ„ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    if realized_all.empty:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        base = realized_all.copy()
        # éŠ˜æŸ„ã‚­ãƒ¼ï¼ˆã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Œã°å„ªå…ˆï¼‰
        sym = None
        if "code_key" in base.columns:
            sym = base["code_key"].fillna(base.get("name_key"))
        elif "name_key" in base.columns:
            sym = base["name_key"]
        else:
            sym = pd.Series(["N/A"]*len(base), index=base.index)
        base = base.assign(symbol=sym)

        named_aggs = {
            "å®Ÿç¾æç›Šåˆè¨ˆ": ("pl", "sum"),
            "å–å¼•å›æ•°": ("pl", "count"),
            "1å›å¹³å‡æç›Š": ("pl", "mean"),  # â† å…ˆé ­ãŒæ•°å­—ã§ã‚‚OKï¼ˆè¾æ›¸å±•é–‹ï¼‰
        }
        by_symbol = base.groupby("symbol").agg(**named_aggs).reset_index().sort_values("å®Ÿç¾æç›Šåˆè¨ˆ", ascending=False)

        by_symbol = _numify_cols(by_symbol, ["å®Ÿç¾æç›Šåˆè¨ˆ","1å›å¹³å‡æç›Š","å–å¼•å›æ•°"], round0=True)

        st.markdown("**å€‹åˆ¥éŠ˜æŸ„**")
        show_numeric_table(by_symbol, {"å®Ÿç¾æç›Šåˆè¨ˆ":"%,.0f","1å›å¹³å‡æç›Š":"%,.0f","å–å¼•å›æ•°":"%,d"}, key="per_symbol")

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½/ä¸‹ä½ï¼‰
        st.markdown("**ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½10 / ä¸‹ä½10ï¼‰**")
        top = by_symbol.head(10).copy()
        worst = by_symbol.tail(10).copy()
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("ä¸Šä½10")
            show_numeric_table(top, {"å®Ÿç¾æç›Šåˆè¨ˆ":"%,.0f","1å›å¹³å‡æç›Š":"%,.0f","å–å¼•å›æ•°":"%,d"}, key="rank_top")
        with c2:
            st.markdown("ä¸‹ä½10")
            show_numeric_table(worst, {"å®Ÿç¾æç›Šåˆè¨ˆ":"%,.0f","1å›å¹³å‡æç›Š":"%,.0f","å–å¼•å›æ•°":"%,d"}, key="rank_worst")

# =========================
# 5) 3åˆ†è¶³ IN/OUT + æŒ‡æ¨™ï¼ˆå…ˆã«æ—¥ä»˜ã‚’é¸ã³ã€ãã®æ—¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ã ã‘é¸æŠï¼‰
# =========================

# --- æ—¢ã«å®šç¾©æ¸ˆã¿ã§ã‚ã‚Œã°å†å®šç¾©ã—ãªã„ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
try:
    guess_name_for_ohlc_key
except NameError:
    def guess_name_for_ohlc_key(key: str, code_to_name: dict) -> str | None:
        code = extract_code_from_ohlc_key(key)
        name = None
        if code:
            name = code_to_name.get(str(code).upper())
        if not name:
            ku = key.upper()
            if "NK2251" in ku or "OSE_NK2251" in ku:
                name = "æ—¥çµŒ225å…ˆç‰©"
            elif "NI225" in ku or "TVC_NI225" in ku:
                name = "æ—¥çµŒå¹³å‡"
        return name

def _nearest_pos_by_ns(idx: pd.DatetimeIndex, t0: pd.Timestamp) -> int:
    if not isinstance(idx, pd.DatetimeIndex):
        idx = pd.DatetimeIndex(idx)
    if idx.tz is None:
        idx = idx.tz_localize(TZ)
    if t0.tzinfo is None:
        t0 = t0.tz_localize(TZ)
    idx_ns = idx.asi8
    t0_ns  = int(pd.Timestamp(t0).value)
    dist = np.abs(idx_ns - t0_ns)
    return int(dist.argmin())

def align_trades_to_ohlc(ohlc: pd.DataFrame, trades: pd.DataFrame, max_gap_min=6):
    if ohlc is None or ohlc.empty or trades is None or trades.empty:
        return pd.DataFrame(columns=["time","price","side","qty","label4"])
    tdf = trades.copy()
    tdf["ç´„å®šæ—¥æ™‚"] = _to_jst_series(tdf["ç´„å®šæ—¥æ™‚"] if "ç´„å®šæ—¥æ™‚" in tdf.columns else None, tdf.index)

    price_col = next((c for c in ["ç´„å®šå˜ä¾¡(å††)","ç´„å®šå˜ä¾¡ï¼ˆå††ï¼‰","ç´„å®šä¾¡æ ¼","ä¾¡æ ¼","ç´„å®šå˜ä¾¡"] if c in tdf.columns), None)
    qty_col   = next((c for c in ["ç´„å®šæ•°é‡(æ ª/å£)","ç´„å®šæ•°é‡","å‡ºæ¥æ•°é‡","æ•°é‡","æ ªæ•°","å‡ºæ¥é«˜","å£æ•°"] if c in tdf.columns), None)
    side_col  = next((c for c in ["å£²è²·","å£²è²·åŒºåˆ†","å£²è²·ç¨®åˆ¥","Side","å–å¼•"] if c in tdf.columns), None)
    if price_col is None:
        for c in tdf.columns:
            if re.search(r"(ç´„å®š)?.*(å˜ä¾¡|ä¾¡æ ¼)", str(c)): price_col = c; break
    if qty_col is None:
        for c in tdf.columns:
            if any(k in str(c) for k in ["æ•°é‡","æ ªæ•°","å£æ•°","å‡ºæ¥é«˜"]): qty_col = c; break

    tdf["price"] = to_numeric_jp(tdf[price_col]) if price_col else np.nan
    tdf["qty"]   = to_numeric_jp(tdf[qty_col])   if qty_col else np.nan
    tdf["side"]  = tdf[side_col].astype(str) if side_col else ""

    def classify_side4(s: str) -> str | None:
        s = str(s)
        if "è²·å»º" in s: return "è²·å»º"
        if "å£²å»º" in s: return "å£²å»º"
        if "å£²åŸ‹" in s: return "å£²åŸ‹"
        if "è²·åŸ‹" in s: return "è²·åŸ‹"
        if ("è²·" in s and ("æ–°è¦" in s or "å»º" in s)) or re.search(r"\bBUY\b.*\b(OPEN|NEW)\b", s, re.I): return "è²·å»º"
        if ("å£²" in s and ("æ–°è¦" in s or "å»º" in s)) or re.search(r"\bSELL\b.*\b(OPEN|NEW)\b", s, re.I): return "å£²å»º"
        if ("å£²" in s and ("è¿”æ¸ˆ" in s or "æ±ºæ¸ˆ" in s)) or re.search(r"\bSELL\b.*\b(CLOSE)\b", s, re.I): return "å£²åŸ‹"
        if ("è²·" in s and ("è¿”æ¸ˆ" in s or "æ±ºæ¸ˆ" in s)) or re.search(r"\bBUY\b.*\b(CLOSE|COVER)\b", s, re.I): return "è²·åŸ‹"
        return None

    tdf["label4"] = tdf["side"].map(classify_side4)

    odf = ohlc.copy()
    tt = _to_jst_series(odf["time"], odf.index)
    odf = odf.set_index(tt).sort_index()

    out_rows = []
    for _, row in tdf.iterrows():
        t0 = row["ç´„å®šæ—¥æ™‚"]
        if pd.isna(t0) or not row.get("label4"):
            continue
        lo = t0 - pd.Timedelta(minutes=max_gap_min)
        hi = t0 + pd.Timedelta(minutes=max_gap_min)
        window = odf.loc[lo:hi]
        if window.empty:
            continue
        pos = _nearest_pos_by_ns(window.index, t0)
        near_time = window.index[pos]
        price_on_bar = window.loc[near_time, "close"]
        out_rows.append({
            "time": near_time, "price": price_on_bar,
            "side": row["side"], "qty": row["qty"], "label4": row["label4"]
        })
    return pd.DataFrame(out_rows)

def make_candle_with_indicators(df: pd.DataFrame, title="", height=560, x_range=None):
    fig = go.Figure()
    fig.add_trace(go.Candlestick(
        x=df["time"], open=df["open"], high=df["high"], low=df["low"], close=df["close"],
        name="OHLC", showlegend=False
    ))
    if "VWAP" in df.columns and df["VWAP"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["VWAP"], name="VWAP", mode="lines",
                                 line=dict(color=COLOR_VWAP, width=1.3)))
    if "MA1" in df.columns and df["MA1"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA1"], name="MA1", mode="lines",
                                 line=dict(color=COLOR_MA1, width=1.3)))
    if "MA2" in df.columns and df["MA2"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA2"], name="MA2", mode="lines",
                                 line=dict(color=COLOR_MA2, width=1.3)))
    if "MA3" in df.columns and df["MA3"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA3"], name="MA3", mode="lines",
                                 line=dict(color=COLOR_MA3, width=1.3)))

    fig.update_layout(
        title=title, height=height, margin=dict(l=10, r=10, t=40, b=10),
        xaxis_rangeslider_visible=False,
        xaxis=dict(showgrid=False, range=x_range),
        yaxis=dict(showgrid=True)
    )
    return fig

with tab5:
    st.markdown("### 3åˆ†è¶³ IN/OUT + æŒ‡æ¨™ï¼ˆVWAP/MA1/MA2/MA3ï¼‰")
    if not ohlc_map:
        st.info("3åˆ†è¶³OHLCãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        dmin, dmax = ohlc_global_date_range(ohlc_map)
        if dmin is None or dmax is None:
            st.info("æœ‰åŠ¹ãªæ—¥æ™‚åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # åˆæœŸå€¤ã¯å½“æ—¥ï¼ˆç¯„å›²å¤–ãªã‚‰ã‚¯ãƒ©ãƒ³ãƒ—ï¼‰
            today_jst = datetime.now(TZ).date()
            default_day = min(max(today_jst, dmin), dmax)

            c1, c2, c3 = st.columns([2,2,1])
            with c1:
                sel_date = st.date_input("è¡¨ç¤ºæ—¥ã‚’é¸æŠ", value=default_day, min_value=dmin, max_value=dmax)
            with c2:
                enlarge = st.toggle("ğŸ” æ‹¡å¤§è¡¨ç¤º", value=False, help="ãƒã‚§ãƒƒã‚¯ã§ãƒãƒ£ãƒ¼ãƒˆã‚’å¤§ããã—ã¾ã™")
            with c3:
                ht = LARGE_CHART_HEIGHT if enlarge else MAIN_CHART_HEIGHT

            # 9:00ã€œ15:30 ã«å›ºå®š
            t0 = pd.Timestamp(f"{sel_date} 09:00", tz=TZ)
            t1 = pd.Timestamp(f"{sel_date} 15:30", tz=TZ)
            x_range = [t0, t1]

            # é¸æŠæ—¥ã®ç´„å®šè¡¨ï¼ˆå…¨éŠ˜æŸ„ï¼‰
            st.markdown("#### ç´„å®šè¡¨ï¼ˆé¸æŠæ—¥ãƒ»å…¨éŠ˜æŸ„ï¼‰")
            if yakujyou_all is None or yakujyou_all.empty:
                st.info("ç´„å®šå±¥æ­´ãŒæœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã™ã€‚")
            else:
                yak_day_all = yakujyou_all.copy()
                y_dtcol = pick_dt_col(yak_day_all) or "ç´„å®šæ—¥"
                yak_day_all["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(yak_day_all) if y_dtcol in yak_day_all.columns else _to_jst_series(pd.Series(pd.NaT, index=yak_day_all.index), yak_day_all.index)
                yak_day_all = yak_day_all[yak_day_all["ç´„å®šæ—¥æ™‚"].notna()]
                yak_day_all = yak_day_all[(yak_day_all["ç´„å®šæ—¥æ™‚"]>=t0) & (yak_day_all["ç´„å®šæ—¥æ™‚"]<=t1)].copy()

                if yak_day_all.empty:
                    st.info(f"{sel_date} ã®å¸‚å ´æ™‚é–“å†…ã«ç´„å®šã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    price_col = next((c for c in ["ç´„å®šå˜ä¾¡(å††)","ç´„å®šå˜ä¾¡ï¼ˆå††ï¼‰","ç´„å®šä¾¡æ ¼","ä¾¡æ ¼","ç´„å®šå˜ä¾¡"] if c in yak_day_all.columns), None)
                    if price_col is None:
                        for c in yak_day_all.columns:
                            if re.search(r"(ç´„å®š)?.*(å˜ä¾¡|ä¾¡æ ¼)", str(c)): price_col = c; break
                    qty_col   = next((c for c in ["ç´„å®šæ•°é‡(æ ª/å£)","ç´„å®šæ•°é‡","å‡ºæ¥æ•°é‡","æ•°é‡","æ ªæ•°","å‡ºæ¥é«˜","å£æ•°"] if c in yak_day_all.columns), None)
                    if qty_col is None:
                        for c in yak_day_all.columns:
                            if any(k in str(c) for k in ["æ•°é‡","æ ªæ•°","å£æ•°","å‡ºæ¥é«˜"]): qty_col = c; break
                    side_col  = next((c for c in ["å£²è²·","å£²è²·åŒºåˆ†","å£²è²·ç¨®åˆ¥","Side","å–å¼•"] if c in yak_day_all.columns), None)

                    disp = pd.DataFrame({
                        "æ™‚åˆ»": yak_day_all["ç´„å®šæ—¥æ™‚"].dt.strftime("%H:%M:%S"),
                        "éŠ˜æŸ„å": yak_day_all.get("name_key", pd.Series([""]*len(yak_day_all), index=yak_day_all.index)),
                        "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰": yak_day_all.get("code_key", pd.Series([""]*len(yak_day_all), index=yak_day_all.index)),
                        "å£²è²·": yak_day_all[side_col] if side_col else "",
                        "ä¾¡æ ¼": to_numeric_jp(yak_day_all[price_col]) if price_col else np.nan,
                        "æ•°é‡": to_numeric_jp(yak_day_all[qty_col]) if qty_col else np.nan,
                    }).sort_values("æ™‚åˆ»")

                    # æ•°å€¤ dtype ã‚’ç¶­æŒï¼ˆã‚¯ãƒªãƒƒã‚¯ã§æ•°å€¤ã‚½ãƒ¼ãƒˆå¯ï¼‰ï¼‹è¦‹ãŸç›®ã¯ã‚«ãƒ³ãƒ
                    disp["ä¾¡æ ¼"] = pd.to_numeric(disp["ä¾¡æ ¼"], errors="coerce").round(0)
                    disp["æ•°é‡"] = pd.to_numeric(disp["æ•°é‡"], errors="coerce")
                    show_numeric_table(disp, {"ä¾¡æ ¼":"%,.0f","æ•°é‡":"%,d"}, key="fills_table")
                    download_button_df(disp, f"â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„å®šè¡¨ {sel_date}ï¼‰", f"fills_{sel_date}.csv")

            # å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ã®ã¿é¸æŠè‚¢ã«
            keys_that_day = []
            for k, df in ohlc_map.items():
                if df is None or df.empty: continue
                vw = df[(df["time"]>=t0) & (df["time"]<=t1)]
                if not vw.empty:
                    keys_that_day.append(k)

            if not keys_that_day:
                st.info("é¸æŠæ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ¥ã®æ—¥ä»˜ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
            else:
                options = sorted(keys_that_day)
                def _fmt_label(k):
                    nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                    return f"{k}ï¼ˆ{nm}ï¼‰" if nm else k

                sel_key = st.selectbox("éŠ˜æŸ„ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã‚’é¸æŠ", options=options, index=0, format_func=_fmt_label)
                sel_name = guess_name_for_ohlc_key(sel_key, CODE_TO_NAME)
                if sel_name:
                    st.caption(f"æƒ³å®šéŠ˜æŸ„å: **{sel_name}**")

                view = ohlc_map[sel_key]
                view = view[(view["time"]>=t0) & (view["time"]<=t1)].copy()
                if view.empty:
                    st.info(f"{sel_key}ï¼š{sel_date} ã®3åˆ†è¶³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    # åŒã‚³ãƒ¼ãƒ‰ã®ç´„å®šã‚’æŠ½å‡ºã—ã¦è¿‘å‚ãƒãƒ¼ã¸ã‚¹ãƒŠãƒƒãƒ—
                    yak = yakujyou_all.copy()
                    if "code_key" in yak.columns:
                        this_code = extract_code_from_ohlc_key(sel_key) or ""
                        if this_code:
                            yak = yak[yak["code_key"].astype(str).str.upper()==this_code.upper()]
                    y_dtcol = pick_dt_col(yak) or "ç´„å®šæ—¥"
                    yak = yak.copy()
                    yak["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(yak) if y_dtcol in yak.columns else _to_jst_series(pd.Series(pd.NaT, index=yak.index), yak.index)
                    yak = yak[yak["ç´„å®šæ—¥æ™‚"].notna()]
                    yak = yak[(yak["ç´„å®šæ—¥æ™‚"]>=t0) & (yak["ç´„å®šæ—¥æ™‚"]<=t1)]

                    trades = align_trades_to_ohlc(view, yak, max_gap_min=6) if not yak.empty else pd.DataFrame(columns=["time","price","side","qty","label4"])
                    title_text = f"{sel_name} [{sel_key}]" if sel_name else sel_key
                    fig = make_candle_with_indicators(view, title=title_text, height=ht, x_range=[t0, t1])

                    marker_styles = {
                        "è²·å»º": dict(symbol="triangle-up",        size=11, color="#2ca02c", line=dict(width=1.2)),
                        "å£²å»º": dict(symbol="triangle-down",      size=11, color="#d62728", line=dict(width=1.2)),
                        "å£²åŸ‹": dict(symbol="triangle-down-open", size=12, color="#9467bd", line=dict(width=1.4)),
                        "è²·åŸ‹": dict(symbol="triangle-up-open",   size=12, color="#1f77b4", line=dict(width=1.4)),
                    }
                    if not trades.empty:
                        for label, mk in marker_styles.items():
                            sub = trades[trades["label4"] == label]
                            if not sub.empty:
                                fig.add_trace(go.Scatter(
                                    x=sub["time"], y=sub["price"], mode="markers",
                                    name=label, marker=mk,
                                    hovertemplate=f"{label}<br>%{{x|%H:%M}}<br>Â¥%{{y:.0f}}<extra></extra>"
                                ))

                    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": True})

            # ä¸‹æ®µï¼šæ—¥çµŒå…ˆç‰©ãƒ»æ—¥çµŒå¹³å‡ï¼ˆã‚ã‚Œã°ï¼‰
            fut_keys = [k for k in keys_that_day if ("NK2251" in k or "OSE_NK2251" in k)]
            idx_keys = [k for k in keys_that_day if ("NI225" in k or "TVC_NI225" in k)]

            st.markdown("#### æ—¥çµŒå…ˆç‰©ï¼ˆNK225miniç­‰ï¼‰")
            if fut_keys:
                k = fut_keys[0]
                df = ohlc_map.get(k)
                vw = df[(df["time"]>=t0) & (df["time"]<=t1)].copy()
                if not vw.empty:
                    nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                    ttl = f"{nm} [{k}]" if nm else k
                    figx = make_candle_with_indicators(vw, title=ttl, height=ht, x_range=[t0, t1])
                    st.plotly_chart(figx, use_container_width=True, config={"displayModeBar": True})
                else:
                    st.info(f"{k}ï¼š{sel_date} ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
            else:
                st.info("æ—¥çµŒå…ˆç‰©ï¼ˆ`OSE_NK2251!` ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

            st.markdown("#### æ—¥çµŒå¹³å‡")
            if idx_keys:
                k = idx_keys[0]
                df = ohlc_map.get(k)
                vw = df[(df["time"]>=t0) & (df["time"]<=t1)].copy()
                if not vw.empty:
                    nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                    ttl = f"{nm} [{k}]" if nm else k
                    figx = make_candle_with_indicators(vw, title=ttl, height=ht, x_range=[t0, t1])
                    st.plotly_chart(figx, use_container_width=True, config={"displayModeBar": True})
                else:
                    st.info(f"{k}ï¼š{sel_date} ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
            else:
                st.info("æ—¥çµŒå¹³å‡ï¼ˆ`TVC_NI225` ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
