import io
import csv
from dataclasses import dataclass
from typing import Optional, Tuple, List

import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go

# æ–‡å­—ã‚³ãƒ¼ãƒ‰æ¨å®šï¼ˆç„¡ãã¦ã‚‚å‹•ãã‚ˆã†ã«tryï¼‰
try:
    from charset_normalizer import from_bytes as cn_from_bytes
except Exception:
    cn_from_bytes = None

st.set_page_config(page_title="3åˆ†è¶³ï¼‹ç´„å®šã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆå®Ÿç¾æç›Šä»˜ãï¼‰", layout="wide")
st.title("CSV/Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼š3åˆ†è¶³ï¼ˆOHLCï¼‰ï¼‹ç´„å®šã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼‹å®Ÿç¾æç›Š")
st.caption("ã‚¿ãƒ–ã”ã¨ã«CSV/Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€‚æ–‡å­—ã‚³ãƒ¼ãƒ‰ãƒ»åŒºåˆ‡ã‚Šã¯è‡ªå‹•åˆ¤åˆ¥ã«ã‚‚å¯¾å¿œã€‚")

# ================= ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆå…±é€šè¨­å®šï¼‰ =================
with st.sidebar:
    st.header("èª­ã¿è¾¼ã¿è¨­å®š")
    encoding = st.selectbox(
        "æ–‡å­—ã‚³ãƒ¼ãƒ‰",
        options=[
            "auto (è‡ªå‹•åˆ¤åˆ¥)", "utf-8", "utf-8-sig",
            "cp932 (Shift_JIS)", "utf-16", "utf-16-le", "utf-16-be",
            "euc_jp", "iso2022_jp"
        ],
        index=0,
        help="ä¸æ˜ãªã¨ãã¯ã€autoã€ã§OKã€‚Excel/TSV/ã‚»ãƒŸã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚Šã‚‚è‡ªå‹•ã§æ¨å®šã—ã¾ã™ã€‚",
    )
    decimal = st.selectbox("å°æ•°ç‚¹è¨˜å·", options=[".", ","], index=0)
    thousands = st.selectbox("æ¡åŒºåˆ‡ã‚Š", options=[None, ",", "_", " "], index=0)

    st.divider()
    st.header("åˆ—åã®å€™è£œï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿½è¨˜OKï¼‰")
    time_candidates = st.text_input("æ™‚åˆ»/æ—¥ä»˜ åˆ—å€™è£œ", value="time,Time,æ—¥æ™‚,æ—¥ä»˜,ç´„å®šæ™‚é–“,ç´„å®šæ—¥,datetime,Datetime")
    o_col = st.text_input("å§‹å€¤ åˆ—å€™è£œ", value="open,Open,å§‹å€¤")
    h_col = st.text_input("é«˜å€¤ åˆ—å€™è£œ", value="high,High,é«˜å€¤")
    l_col = st.text_input("å®‰å€¤ åˆ—å€™è£œ", value="low,Low,å®‰å€¤")
    c_col = st.text_input("çµ‚å€¤ åˆ—å€™è£œ", value="close,Close,çµ‚å€¤")
    v_col = st.text_input("å‡ºæ¥é«˜ åˆ—å€™è£œ", value="volume,å‡ºæ¥é«˜")
    vwap_col = st.text_input("VWAP åˆ—å€™è£œ", value="VWAP,vwap")

# ================= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =================
def _drop_tz_index(idx):
    """DatetimeIndex ã® tz ã‚’å¤–ã—ã¦ naive ã«çµ±ä¸€"""
    if isinstance(idx, pd.DatetimeIndex):
        try:
            return idx.tz_localize(None)
        except Exception:
            try:
                return idx.tz_convert(None)
            except Exception:
                return idx
    return idx

def _drop_tz_series(s: pd.Series) -> pd.Series:
    """Series[datetime] ã® tz ã‚’å¤–ã—ã¦ naive ã«çµ±ä¸€"""
    if not isinstance(s, pd.Series):
        return s
    # ä¸€åº¦ datetime å‹ã¸
    s = pd.to_datetime(s, errors="coerce")
    # tz ã‚’å¤–ã™
    try:
        return s.dt.tz_localize(None)
    except Exception:
        try:
            return s.dt.tz_convert(None)
        except Exception:
            return s

def _split_candidates(s: str) -> List[str]:
    return [x.strip() for x in s.split(",") if x.strip()]

def _find_first(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    for c in candidates:
        if c in df.columns:
            return c
    return None

@st.cache_data(show_spinner=True)
def load_text_table(file_bytes: bytes, encoding_choice: str, decimal: str, thousands):
    """
    CSV/TSV/ã‚»ãƒŸã‚³ãƒ­ãƒ³/ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ã‚’èª­ã¿è¾¼ã‚€ã€‚
    - æ–‡å­—ã‚³ãƒ¼ãƒ‰ï¼šè‡ªå‹•åˆ¤åˆ¥ + BOMãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹ + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€™è£œ
    - åŒºåˆ‡ã‚Šæ–‡å­—ï¼šcsv.Sniffer + ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹
    """
    # æ–‡å­—ã‚³ãƒ¼ãƒ‰å€™è£œã‚’çµ„ã¿ç«‹ã¦
    candidates = []
    if encoding_choice.startswith("auto"):
        b = file_bytes
        if b.startswith(b"\xff\xfe") or b.startswith(b"\xfe\xff"):
            candidates.append("utf-16")
        elif b.startswith(b"\xef\xbb\xbf"):
            candidates.append("utf-8-sig")
        if cn_from_bytes is not None:
            try:
                best = cn_from_bytes(b).best()
                if best and best.encoding:
                    candidates.insert(0, best.encoding)
            except Exception:
                pass
        candidates += ["utf-8", "cp932", "utf-16", "utf-16-le", "utf-16-be", "euc_jp", "iso2022_jp"]
    else:
        candidates = ["cp932" if "cp932" in encoding_choice else encoding_choice]

    last_err = None
    for enc in dict.fromkeys(candidates):  # é‡è¤‡é™¤å»ã—ã¤ã¤é †ç•ªç¶­æŒ
        try:
            text = file_bytes.decode(enc, errors="strict")
            sample = text[:20000]
            sep = None
            try:
                dialect = csv.Sniffer().sniff(sample, delimiters=[",", "\t", ";", "|"])
                sep = dialect.delimiter
            except Exception:
                # ã–ã£ãã‚Šãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹
                if sample.count("\t") > sample.count(",") and sample.count("\t") >= 2:
                    sep = "\t"
                elif sample.count(";") > sample.count(",") and sample.count(";") >= 2:
                    sep = ";"
                elif sample.count("|") > sample.count(",") and sample.count("|") >= 2:
                    sep = "|"

            df = pd.read_csv(
                io.StringIO(text),
                sep=sep,
                decimal=decimal,
                thousands=None if thousands in (None, "None", "") else thousands,
                engine="python",
            )
            df.attrs["used_encoding"] = enc
            df.attrs["used_sep"] = sep or ","
            return df
        except Exception as e:
            last_err = e
            continue
    # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯æœ€å¾Œã®ä¾‹å¤–ã‚’æŠ•ã’ã‚‹
    raise last_err

@st.cache_data(show_spinner=True)
def load_any_table(file_name: str, file_bytes: bytes, encoding_choice: str, decimal: str, thousands):
    """
    æ‹¡å¼µå­ã§åˆ†å²ï¼š.xlsx ã¯ Excelã€ãã®ä»–ã¯ãƒ†ã‚­ã‚¹ãƒˆè¡¨ã¨ã¿ãªã™
    """
    if file_name.lower().endswith(".xlsx"):
        return pd.read_excel(io.BytesIO(file_bytes), engine="openpyxl")
    else:
        return load_text_table(file_bytes, encoding_choice, decimal, thousands)

def parse_datetime_index(df: pd.DataFrame, time_cols: List[str]) -> Tuple[pd.DataFrame, Optional[str]]:
    col = _find_first(df, time_cols)
    if col is None:
        return df, None
    s = _drop_tz_series(df[col])                 # â† tz ã‚’é™¤å»ã—ã¦ã‹ã‚‰
    df[col] = s
    df = df.sort_values(col)
    try:
        df = df.set_index(col)
        df.index = _drop_tz_index(df.index)      # â† å¿µã®ãŸã‚ index å´ã‚‚ tz é™¤å»
    except Exception:
        pass
    return df, col


@dataclass
class OHLCCols:
    open: str
    high: str
    low: str
    close: str
    volume: Optional[str] = None
    vwap: Optional[str] = None

def detect_ohlc_cols(df: pd.DataFrame,
                     o_cands: List[str], h_cands: List[str],
                     l_cands: List[str], c_cands: List[str],
                     v_cands: List[str], vwap_cands: List[str]) -> Optional[OHLCCols]:
    o = _find_first(df, o_cands)
    h = _find_first(df, h_cands)
    l = _find_first(df, l_cands)
    c = _find_first(df, c_cands)
    if not all([o, h, l, c]):
        return None
    v = _find_first(df, v_cands)
    vwap = _find_first(df, vwap_cands)
    return OHLCCols(open=o, high=h, low=l, close=c, volume=v, vwap=vwap)

def cast_numeric(df: pd.DataFrame, cols: List[Optional[str]]):
    for col in cols:
        if col and col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

# ====== å£²è²·/INOUT æ­£è¦åŒ– & æ•°å€¤ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚° ======
def normalize_side(val: object) -> str | float:
    """BUY/SELL ã‚’æ±ºã‚ã‚‹ï¼ˆè²·å»º/å£²å»º/è²·åŸ‹/å£²åŸ‹ ã«å¯¾å¿œã€‚IN/OUTã¯è¿”ã•ãªã„ï¼‰"""
    s = str(val).strip()
    sl = s.lower()
    # è‹±èªãƒ»ç•¥ç§°
    if sl in ["buy", "b", "long", "ç¾è²·", "æ–°è¦è²·"]:
        return "BUY"
    if sl in ["sell", "s", "short", "ç¾å£²", "æ–°è¦å£²"]:
        return "SELL"
    # æ—¥æœ¬èªï¼ˆå»º/åŸ‹ å«ã‚€ï¼‰
    if "è²·" in s:   # è²·å»º/è²·åŸ‹/è²· ãªã©
        return "BUY"
    if "å£²" in s:   # å£²å»º/å£²åŸ‹/å£² ãªã©
        return "SELL"
    return np.nan

def normalize_inout(val: object) -> str | float:
    """IN/OUT ã‚’æ±ºã‚ã‚‹ï¼ˆå»º=IN / åŸ‹=OUT ã‚’åˆ¤å®šï¼‰"""
    s = str(val).strip()
    sl = s.lower()
    if sl in ["in", "entry", "ã‚¨ãƒ³ãƒˆãƒªãƒ¼", "æ–°è¦", "æ–°è¦å»º"] or ("å»º" in s):
        return "IN"
    if sl in ["out", "exit", "æ±ºæ¸ˆ", "è¿”æ¸ˆ", "æ‰‹ä»•èˆã„", "ã‚¯ãƒ­ãƒ¼ã‚º"] or ("åŸ‹" in s):
        return "OUT"
    return np.nan

def clean_numeric_series(s: pd.Series) -> pd.Series:
    """Â¥, å††, ã‚«ãƒ³ãƒ, å…¨è§’ãƒã‚¤ãƒŠã‚¹, (123) â†’ -123 ãªã©ã‚’å¸åã—ã¦æ•°å€¤åŒ–"""
    t = s.astype(str)
    t = t.str.replace(r"\((\s*[\d,\.]+)\)", r"-\1", regex=True)  # (123) -> -123
    t = t.str.replace("âˆ’", "-", regex=False)                    # å…¨è§’ãƒã‚¤ãƒŠã‚¹
    t = t.str.replace(",", "", regex=False)                      # æ¡åŒºåˆ‡ã‚Š
    t = t.str.replace("Â¥", "", regex=False).str.replace("å††", "", regex=False)
    t = t.str.replace("%", "", regex=False)                      # %é™¤å»ï¼ˆå¿…è¦ãªã‚‰ï¼‰
    t = t.str.replace(r"[^\d\.\-\+eE]", "", regex=True)          # æ®‹ã‚Šã®è¨˜å·ã‚’é™¤å»
    return pd.to_numeric(t, errors="coerce")

# ================= ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆç´„å®šã‚’ã‚¿ãƒ–1ã§ä½¿ã†ï¼‰ =================
if "trades_df" not in st.session_state:
    st.session_state["trades_df"] = None
if "trades_time_col" not in st.session_state:
    st.session_state["trades_time_col"] = None
if "trades_price_col" not in st.session_state:
    st.session_state["trades_price_col"] = None
if "trades_side_col" not in st.session_state:
    st.session_state["trades_side_col"] = None
if "trades_inout_col" not in st.session_state:
    st.session_state["trades_inout_col"] = None

# ================= ã‚¿ãƒ– =================
tab1, tab2, tab3 = st.tabs(["â‘  3åˆ†è¶³ï¼ˆOHLCï¼‰", "â‘¡ ç´„å®šå±¥æ­´", "â‘¢ å®Ÿç¾æç›Š"])

# ---------- â‘  3åˆ†è¶³ï¼ˆOHLCï¼‰ ----------
with tab1:
    st.subheader("3åˆ†è¶³ï¼ˆOHLCï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆCSV/TSV/Excelï¼‰")
    ohlc_file = st.file_uploader("time, open, high, low, close, volume, VWAP ãªã©ã‚’å«ã‚€è¡¨",
                                 type=["csv", "txt", "xlsx"], key="ohlc_upl")

    if ohlc_file is None:
        st.info("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
    else:
        try:
            df_ohlc = load_any_table(ohlc_file.name, ohlc_file.getvalue(), encoding, decimal, thousands)
        except Exception as e:
            st.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚„åŒºåˆ‡ã‚Šã‚’è¦‹ç›´ã™ã‹ã€Excel/CSVã®å½¢å¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            st.exception(e)
            st.stop()

        # å‚è€ƒæƒ…å ±ï¼ˆä½•ã§èª­ã‚ãŸã‹ï¼‰
        used_enc = df_ohlc.attrs.get("used_encoding")
        used_sep = df_ohlc.attrs.get("used_sep")
        if used_enc or used_sep:
            st.caption(f"ğŸ” encoding={used_enc or 'Excel'}, sep={used_sep or '(Excel)'}")

        # æ™‚åˆ»â†’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        df_ohlc, ohlc_time_col = parse_datetime_index(df_ohlc, _split_candidates(time_candidates))
        # åˆ—æ¤œå‡º
        cols = detect_ohlc_cols(
            df_ohlc,
            _split_candidates(o_col), _split_candidates(h_col),
            _split_candidates(l_col), _split_candidates(c_col),
            _split_candidates(v_col), _split_candidates(vwap_col),
        )
        if cols is None:
            st.error("OHLCåˆ—ï¼ˆå§‹å€¤/é«˜å€¤/å®‰å€¤/çµ‚å€¤ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å€™è£œã«å®Ÿéš›ã®åˆ—åã‚’è¿½è¨˜ã—ã¦å†èª­è¾¼ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # æ•°å€¤åŒ–
        cast_numeric(df_ohlc, [cols.open, cols.high, cols.low, cols.close, cols.volume, cols.vwap])

        st.write("#### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df_ohlc.head(100))

        # è¡¨ç¤ºç¯„å›²
        st.write("#### è¡¨ç¤ºç¯„å›²ï¼ˆä»»æ„ï¼‰")
        if isinstance(df_ohlc.index, pd.DatetimeIndex) and len(df_ohlc) > 1:
            min_d, max_d = df_ohlc.index.min(), df_ohlc.index.max()
            rng = st.slider("æœŸé–“ã‚’æŒ‡å®š", min_value=min_d.to_pydatetime(), max_value=max_d.to_pydatetime(),
                            value=(min_d.to_pydatetime(), max_d.to_pydatetime()))
            view = df_ohlc.loc[(df_ohlc.index >= rng[0]) & (df_ohlc.index <= rng[1])].copy()
        else:
            view = df_ohlc.copy()

        # ãƒ­ãƒ¼ã‚½ã‚¯è¶³
        fig = go.Figure()
        x = view.index if isinstance(view.index, pd.DatetimeIndex) else np.arange(len(view))
        fig.add_trace(go.Candlestick(
            x=x, open=view[cols.open], high=view[cols.high],
            low=view[cols.low], close=view[cols.close], name="OHLC",
        ))

        # VWAP
        if cols.vwap and cols.vwap in view.columns:
            fig.add_trace(go.Scatter(x=x, y=view[cols.vwap], mode="lines", name="VWAP", opacity=0.85))

        # ç´„å®šã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆå®‰å…¨ç‰ˆï¼‰
        overlay_ok = st.checkbox(
            "ç´„å®šå±¥æ­´ã‚’é‡ã­ã‚‹ï¼ˆã‚¿ãƒ–â‘¡ã§èª­ã¿è¾¼ã‚€ã¨æœ‰åŠ¹ï¼‰",
            value=True,
            disabled=st.session_state["trades_df"] is None,
        )
        
        if overlay_ok and st.session_state["trades_df"] is not None:
            tdf = st.session_state["trades_df"].copy()
        
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰åˆ—åã‚’å–å¾—ï¼ˆNone å®‰å…¨ï¼‰
            t_time_col  = st.session_state.get("trades_time_col")
            t_price_col = st.session_state.get("trades_price_col")
            t_side_norm = "SIDE_NORM" if "SIDE_NORM" in tdf.columns else None
            t_inout_norm= st.session_state.get("trades_inout_col")
        
            # åˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆç„¡ã‘ã‚Œã°ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã›ãšæ³¨æ„æ›¸ãï¼‰
            if not t_time_col or t_time_col not in tdf.columns:
                st.caption("âš  ç´„å®šã®æ™‚åˆ»åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            else:
                # ä¾¡æ ¼åˆ—ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
                if t_price_col and t_price_col in tdf.columns and not pd.api.types.is_numeric_dtype(tdf[t_price_col]):
                    tdf[t_price_col] = clean_numeric_series(tdf[t_price_col])
        
                # è¡¨ç¤ºæœŸé–“å†…ã«çµã‚‹ï¼ˆä¸¡è€…ã¨ã‚‚ tz ãªã—ã«çµ±ä¸€ã—ã¦æ¯”è¼ƒï¼‰
                if isinstance(view.index, pd.DatetimeIndex):
                    idx_naive = _drop_tz_index(view.index)
                    t_series  = _drop_tz_series(tdf[t_time_col])
                    if len(idx_naive) > 0:
                        min_ts, max_ts = idx_naive.min(), idx_naive.max()
                        mask = (t_series >= min_ts) & (t_series <= max_ts)
                        tdf = tdf[mask]
        
                # 1) BUY/SELL ãŒã‚ã‚Œã°æç”»
                if t_side_norm and t_side_norm in tdf.columns and t_price_col and t_price_col in tdf.columns:
                    buys  = tdf[tdf[t_side_norm] == "BUY"]
                    sells = tdf[tdf[t_side_norm] == "SELL"]
                    if len(buys) > 0:
                        fig.add_trace(go.Scatter(
                            x=buys[t_time_col], y=buys[t_price_col], mode="markers",
                            name="è²·", marker_symbol="triangle-up", marker_size=10, opacity=0.9,
                        ))
                    if len(sells) > 0:
                        fig.add_trace(go.Scatter(
                            x=sells[t_time_col], y=sells[t_price_col], mode="markers",
                            name="å£²", marker_symbol="triangle-down", marker_size=10, opacity=0.9,
                        ))
        
                # 2) IN/OUT ãŒã‚ã‚Œã°æç”»ï¼ˆSIDE ãŒç„¡ãã¦ã‚‚è¡¨ç¤ºï¼‰
                if t_inout_norm and t_inout_norm in tdf.columns and t_price_col and t_price_col in tdf.columns:
                    inns = tdf[tdf[t_inout_norm] == "IN"]
                    outs = tdf[tdf[t_inout_norm] == "OUT"]
                    if len(inns) > 0:
                        fig.add_trace(go.Scatter(
                            x=inns[t_time_col], y=inns[t_price_col], mode="markers",
                            name="IN", marker_symbol="x", marker_size=9, opacity=0.9,
                        ))
                    if len(outs) > 0:
                        fig.add_trace(go.Scatter(
                            x=outs[t_time_col], y=outs[t_price_col], mode="markers",
                            name="OUT", marker_symbol="diamond-open", marker_size=11, opacity=0.9,
                        ))

        st.plotly_chart(fig, use_container_width=True)

# ---------- â‘¡ ç´„å®šå±¥æ­´ ----------
with tab2:
    st.subheader("ç´„å®šå±¥æ­´ï¼ˆCSV/TSV/Excelï¼‰")
    st.caption("æƒ³å®šåˆ—ï¼š ç´„å®šæ—¥/ç´„å®šæ™‚é–“ / å£²è²· / ç´„å®šæ•° / ç´„å®šå˜ä¾¡ï¼ˆåˆ—åã¯ä»»æ„ã€‚ä¸‹ã®å€™è£œã§æŒ‡å®šï¼‰")
    trades_file = st.file_uploader("ç´„å®šå±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«", type=["csv", "txt", "xlsx"], key="trades_upl")

    # åˆ—å€™è£œï¼ˆæ—¢å®šã«ã€Œç´„å®šæ—¥ã€ã€Œç´„å®šå˜ä¾¡(å††)ã€ãªã©ã‚‚å«ã‚ã‚‹ï¼‰
    t_time_c = st.text_input("ï¼ˆç´„å®šï¼‰æ™‚åˆ» åˆ—å€™è£œ", value="ç´„å®šæ—¥,ç´„å®šæ™‚é–“,æ—¥æ™‚,æ—¥ä»˜,time,Time")
    t_side_c = st.text_input("å£²è²· åˆ—å€™è£œ", value="å£²è²·,side,Side,åŒºåˆ†,å–å¼•")
    t_qty_c  = st.text_input("æ•°é‡ï¼ˆç´„å®šæ•°ï¼‰ åˆ—å€™è£œ", value="ç´„å®šæ•°,æ•°é‡,æ ªæ•°,ç´„å®šæ•°é‡,Qty,qty,ã‚µã‚¤ã‚º,ç´„å®šæ•°é‡(æ ª/å£)")
    t_price_c= st.text_input("ä¾¡æ ¼ï¼ˆç´„å®šå˜ä¾¡ï¼‰ åˆ—å€™è£œ", value="ç´„å®šå˜ä¾¡,ç´„å®šå˜ä¾¡(å††),å˜ä¾¡,ä¾¡æ ¼,Price,price")
    t_inout_c= st.text_input("IN/OUT åˆ—å€™è£œï¼ˆæ–°è¦/è¿”æ¸ˆãƒ»ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆ ç­‰ï¼‰",
                             value="IN/OUT,INOUT,æ–°è¦è¿”æ¸ˆ,æ–°è¦/è¿”æ¸ˆ,entry_exit,EntryExit,åŒºåˆ†2,å–å¼•ç¨®åˆ¥")

    if trades_file is None:
        st.info("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã¶ã¨ã‚¿ãƒ–â‘ ã«â€œè²·/å£²/IN/OUTãƒãƒ¼ã‚«ãƒ¼â€ã‚’é‡ã­ã‚‰ã‚Œã¾ã™ã€‚")
    else:
        try:
            df_tr = load_any_table(trades_file.name, trades_file.getvalue(), encoding, decimal, thousands)
        except Exception as e:
            st.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.exception(e)
            st.stop()

        used_enc = df_tr.attrs.get("used_encoding")
        used_sep = df_tr.attrs.get("used_sep")
        if used_enc or used_sep:
            st.caption(f"ğŸ” encoding={used_enc or 'Excel'}, sep={used_sep or '(Excel)'}")

        # ---- åˆ—æ¤œå‡ºï¼ˆä¾å­˜é–¢æ•°ãªã—ã®å®‰å…¨ç‰ˆï¼‰----
        def pick_col(df: pd.DataFrame, cand_str: str) -> Optional[str]:
            cands = [s.strip() for s in str(cand_str).split(",") if s.strip()]
            for c in cands:
                if c in df.columns:
                    return c
            return None

        t_time  = pick_col(df_tr, t_time_c)
        t_side  = pick_col(df_tr, t_side_c)
        t_qty   = pick_col(df_tr, t_qty_c)
        t_price = pick_col(df_tr, t_price_c)
        t_inout = pick_col(df_tr, t_inout_c)

        # å‹å¤‰æ›
        if t_time:
            df_tr[t_time] = pd.to_datetime(df_tr[t_time], errors="coerce")
            df_tr[t_time] = _drop_tz_series(df_tr[t_time])   # â† è¿½åŠ ï¼štz ã‚’å¤–ã™

        for col in [t_qty, t_price]:
            if col and col in df_tr.columns:
                df_tr[col] = clean_numeric_series(df_tr[col])

        # æ­£è¦åŒ–ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆIN/OUTåˆ—ãŒç„¡ãã¦ã‚‚ å£²è²· ã‹ã‚‰å°å‡ºï¼‰
        if t_side and t_side in df_tr.columns:
            df_tr["SIDE_NORM"] = df_tr[t_side].apply(normalize_side)

        if t_inout and t_inout in df_tr.columns:
            df_tr["INOUT_NORM"] = df_tr[t_inout].apply(normalize_inout)
        elif t_side and t_side in df_tr.columns:
            df_tr["INOUT_NORM"] = df_tr[t_side].apply(normalize_inout)

        st.write("#### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df_tr.head(200))

        with st.expander("æ¤œå‡ºçŠ¶æ³ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰"):
            st.write({
                "time_col": t_time, "price_col": t_price, "side_col": t_side, "inout_col": t_inout
            })
            if "SIDE_NORM" in df_tr.columns:
                st.write("SIDE_NORM counts:", df_tr["SIDE_NORM"].value_counts(dropna=False))
            if "INOUT_NORM" in df_tr.columns:
                st.write("INOUT_NORM counts:", df_tr["INOUT_NORM"].value_counts(dropna=False))

        with st.expander("ç°¡æ˜“ã‚µãƒãƒª"):
            total_rows = len(df_tr)
            buy_n = int(df_tr["SIDE_NORM"].eq("BUY").sum()) if "SIDE_NORM" in df_tr.columns else 0
            sell_n = int(df_tr["SIDE_NORM"].eq("SELL").sum()) if "SIDE_NORM" in df_tr.columns else 0
            st.write(f"- è¡Œæ•°: {total_rows} / è²·: {buy_n} / å£²: {sell_n}")
            if t_qty:
                st.write(f"- ç·æ•°é‡: {pd.to_numeric(df_tr[t_qty], errors='coerce').sum():,.0f}")
            if t_price:
                st.write(f"- ä¾¡æ ¼ï¼ˆç´„å®šå˜ä¾¡ï¼‰min/median/max: {df_tr[t_price].min()} / {df_tr[t_price].median()} / {df_tr[t_price].max()}")

        # ã‚¿ãƒ–â‘ ã§ä½¿ã†ãŸã‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
        st.session_state["trades_df"] = df_tr
        st.session_state["trades_time_col"] = t_time
        st.session_state["trades_price_col"] = t_price
        st.session_state["trades_side_col"] = t_side
        st.session_state["trades_inout_col"] = "INOUT_NORM" if "INOUT_NORM" in df_tr.columns else None

# ---------- â‘¢ å®Ÿç¾æç›Š ----------
with tab3:
    st.subheader("å®Ÿç¾æç›Šï¼ˆCSV/TSV/Excelï¼‰")
    st.caption("æƒ³å®šåˆ—ï¼š æ—¥ä»˜ / å®Ÿç¾æç›Šï¼ˆåˆ—åè‡ªç”±ã€ä¸‹ã®å€™è£œã§æŒ‡å®šï¼‰")
    pnl_file = st.file_uploader("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«", type=["csv", "txt", "xlsx"], key="pnl_upl")
    d_col_cand = st.text_input("æ—¥ä»˜ åˆ—å€™è£œ", value="æ—¥ä»˜,æ—¥æ™‚,Date,date")
    pnl_col_cand = st.text_input("æç›Š åˆ—å€™è£œ", value="å®Ÿç¾æç›Š,æç›Š,PnL,Profit,profit")

    if pnl_file is None:
        st.info("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã¶ã¨æ¨ç§»ã¨ç´¯ç©ã‚’æç”»ã—ã¾ã™ã€‚")
    else:
        try:
            df_pnl = load_any_table(pnl_file.name, pnl_file.getvalue(), encoding, decimal, thousands)
        except Exception as e:
            st.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.exception(e)
            st.stop()

        used_enc = df_pnl.attrs.get("used_encoding")
        used_sep = df_pnl.attrs.get("used_sep")
        if used_enc or used_sep:
            st.caption(f"ğŸ” encoding={used_enc or 'Excel'}, sep={used_sep or '(Excel)'}")

        d_col = _find_first(df_pnl, _split_candidates(d_col_cand))

        # åˆ—å€™è£œã‹ã‚‰è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã«å‚™ãˆã¦ã€ã‚†ã‚‹ã‚æ¤œå‡º
        p_col = _find_first(df_pnl, _split_candidates(pnl_col_cand))
        if p_col is None:
            tokens = ["æ", "ç›Š", "æç›Š", "å®Ÿç¾", "pl", "p/l", "profit", "pnl", "realized"]
            cand_names = [c for c in df_pnl.columns if any(t in str(c).lower() for t in tokens)]
            best_col, best_ratio = None, 0.0
            for c in cand_names:
                ser = clean_numeric_series(df_pnl[c])
                ratio = ser.notna().mean()
                if ratio > best_ratio:
                    best_ratio, best_col = ratio, c
            if best_col is not None and best_ratio >= 0.5:
                p_col = best_col

        if d_col:
            df_pnl[d_col] = pd.to_datetime(df_pnl[d_col], errors="coerce")
            df_pnl = df_pnl.sort_values(d_col).set_index(d_col)

        if p_col is None:
            st.error("æç›Šåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ—å€™è£œã«å®Ÿéš›ã®åˆ—åã‚’è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚")
        else:
            # é€šè²¨è¨˜å·ãƒ»ã‚«ãƒ³ãƒãƒ»æ‹¬å¼§ãƒ»å…¨è§’ãƒã‚¤ãƒŠã‚¹ãªã©ã‚’å¸å
            df_pnl[p_col] = clean_numeric_series(df_pnl[p_col])

            st.write("#### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df_pnl[[p_col]].head(500))

            st.write("#### æ—¥æ¬¡ï¼ˆã¾ãŸã¯æ™‚ç³»åˆ—ï¼‰æ¨ç§»")
            st.line_chart(df_pnl[[p_col]], height=300)

            st.write("#### ç´¯ç©æç›Š")
            cum = df_pnl[[p_col]].cumsum().rename(columns={p_col: "ç´¯ç©"})
            st.line_chart(cum, height=300)
