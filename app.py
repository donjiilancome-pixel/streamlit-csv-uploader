# -*- coding: utf-8 -*-
import io
import re
import os
from datetime import datetime, date, time, timedelta

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st

# =============================
# åŸºæœ¬è¨­å®š
# =============================
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", layout="wide")

TZ = "Asia/Tokyo"
COLOR_VWAP = "#888888"   # ã‚°ãƒ¬ãƒ¼
COLOR_MA1  = "#2ca02c"   # ç·‘
COLOR_MA2  = "#ff7f0e"   # ã‚ªãƒ¬ãƒ³ã‚¸
COLOR_MA3  = "#1f77b4"   # é’
MAIN_CHART_HEIGHT  = 420
LARGE_CHART_HEIGHT = 620

# =============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =============================
@st.cache_data(show_spinner=False)
def read_csv_safely(file, encoding="utf-8-sig", **kwargs):
    errors = []
    for enc in [encoding, "cp932", "utf-8", "ISO-2022-JP", "latin-1"]:
        try:
            file.seek(0)
            return pd.read_csv(file, encoding=enc, **kwargs)
        except Exception as e:
            errors.append(f"{enc}: {e}")
    raise ValueError("æ–‡å­—ã‚³ãƒ¼ãƒ‰ã®è§£é‡ˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚\n" + "\n".join(errors))


def to_numeric_jp(s):
    if s is None:
        return pd.Series(dtype=float)
    return (
        pd.to_numeric(
            pd.Series(s, dtype="object")
            .astype(str)
            .str.replace(",", "", regex=False)
            .str.replace("å††", "", regex=False)
            .str.replace("%", "", regex=False)
            .str.replace("\u2212", "-", regex=False)  # å…¨è§’ãƒã‚¤ãƒŠã‚¹
            .str.replace("âˆ’", "-", regex=False)       # åˆ¥ã®å…¨è§’ãƒã‚¤ãƒŠã‚¹
            .str.strip(),
            errors="coerce",
        )
    )


def _to_jst_series(s, index_like):
    if s is None:
        return pd.Series(pd.NaT, index=index_like)
    dt = pd.to_datetime(s, errors="coerce")
    if isinstance(dt, pd.Series):
        if getattr(dt.dt, "tz", None) is None:
            dt = dt.dt.tz_localize(TZ)
        else:
            dt = dt.dt.tz_convert(TZ)
    else:
        if dt.tzinfo is None:
            dt = dt.tz_localize(TZ)
        else:
            dt = dt.tz_convert(TZ)
    return dt


def ensure_jst(dt_like):
    dt = pd.to_datetime(dt_like, errors="coerce")
    if isinstance(dt, pd.Series):
        if getattr(dt.dt, "tz", None) is None:
            dt = dt.dt.tz_localize(TZ)
        else:
            dt = dt.dt.tz_convert(TZ)
    else:
        if dt.tzinfo is None:
            dt = dt.tz_localize(TZ)
        else:
            dt = dt.tz_convert(TZ)
    return dt


def pick_dt_col(df: pd.DataFrame):
    if df is None or df.empty:
        return None
    for c in ["ç´„å®šæ—¥æ™‚_final", "ç´„å®šæ—¥æ™‚_æ¨å®š", "ç´„å®šæ—¥æ™‚", "æ—¥æ™‚", "æ—¥ä»˜", "ç´„å®šæ—¥"]:
        if c in df.columns:
            return c
    # ã‚ã‚Œã°å…ˆé ­ã® datetime ã£ã½ã„åˆ—
    for c in df.columns:
        if re.search(r"(time|date|æ—¥æ™‚|æ—¥ä»˜)", str(c), flags=re.I):
            return c
    return None


def pick_dt_with_optional_time(df: pd.DataFrame):
    col = pick_dt_col(df)
    if col is None:
        return pd.Series(pd.NaT, index=df.index)
    dt = pd.to_datetime(df[col], errors="coerce")
    # æ—¥ä»˜ã®ã¿ï¼ˆæ™‚é–“æˆåˆ†ãŒæ¬ è½ï¼‰ã‚’åˆ¤å®š -> NaTã®ã¾ã¾æ‰±ã„ï¼ˆæ™‚é–“åˆ¥é›†è¨ˆã§ã¯é™¤å¤–ï¼‰
    # ãŸã ã—3åˆ†è¶³ã‚¿ãƒ–ã®ç´„å®šè¡¨ãªã©ã§ã¯æ—¥æ¬¡ãƒ•ã‚£ãƒ«ã‚¿ã®ãŸã‚ã« 00:00 ãŒæ··ã–ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§æ³¨æ„
    # ã“ã“ã§ã¯ä¸€å¾‹ã«JSTä»˜ä¸ã®ã¿ï¼ˆ0æ™‚ã¯è¡¨ç¤ºå´ã§é™¤å¤–å¯ï¼‰
    if isinstance(dt, pd.Series):
        if getattr(dt.dt, "tz", None) is None:
            dt = dt.dt.tz_localize(TZ)
        else:
            dt = dt.dt.tz_convert(TZ)
    else:
        if dt.tzinfo is None:
            dt = dt.tz_localize(TZ)
        else:
            dt = dt.tz_convert(TZ)
    return dt


def extract_code_from_ohlc_key(key: str) -> str | None:
    # ä¾‹: "TSE_9984, 3_xxxx.csv" -> "TSE_9984"
    base = os.path.basename(str(key))
    head = base.split(",")[0]
    head = head.replace(".csv", "")
    m = re.search(r"([A-Z]{2,}_[0-9A-Z!]+)", head, flags=re.I)
    if m:
        return m.group(1).upper()
    # ãã‚Œä»¥å¤–ï¼ˆæŒ‡æ•°ãªã©ï¼‰ã¯ãã®ã¾ã¾è¿”ã™
    return head.strip() if head else None


def ohlc_global_date_range(ohlc_map: dict):
    tmins, tmaxs = [], []
    for _, df in ohlc_map.items():
        if df is None or df.empty or "time" not in df.columns:
            continue
        tt = ensure_jst(df["time"])  # tz-aware
        tmins.append(tt.min().date())
        tmaxs.append(tt.max().date())
    if not tmins:
        return None, None
    return min(tmins), max(tmaxs)


def compute_vwap_by_day(df: pd.DataFrame):
    # volume åˆ—ã®æ¤œå‡º
    vol_col = None
    for c in ["volume", "å‡ºæ¥é«˜", "å‡ºæ¥é«˜(æ ª)", "å‡ºæ¥é«˜(å£)", "Volume", "VOL"]:
        if c in df.columns:
            vol_col = c
            break
    if vol_col is None:
        return df  # VWAPä¸å¯
    out = df.copy()
    out["_pv"] = out["close"] * to_numeric_jp(out[vol_col])
    tt = ensure_jst(out["time"])
    out["_date"] = tt.dt.date
    out["_cum_pv"] = out.groupby("_date")["_pv"].cumsum()
    out["_cum_v"]  = out.groupby("_date")[vol_col].cumsum()
    out["VWAP"] = out["_cum_pv"] / out["_cum_v"].replace(0, np.nan)
    return out.drop(columns=["_pv", "_date", "_cum_pv", "_cum_v"])


def add_mas(df: pd.DataFrame, w1=5, w2=20, w3=60):
    out = df.copy()
    if "close" in out.columns:
        out["MA1"] = out["close"].rolling(w1, min_periods=1).mean()
        out["MA2"] = out["close"].rolling(w2, min_periods=1).mean()
        out["MA3"] = out["close"].rolling(w3, min_periods=1).mean()
    return out


def guess_name_for_ohlc_key(key: str, code_to_name: dict) -> str | None:
    code = extract_code_from_ohlc_key(key)
    name = None
    if code:
        name = code_to_name.get(str(code).upper())
    if not name:
        ku = str(key).upper()
        if "NK2251" in ku or "OSE_NK2251" in ku:
            name = "æ—¥çµŒ225å…ˆç‰©"
        elif "NI225" in ku or "TVC_NI225" in ku:
            name = "æ—¥çµŒå¹³å‡"
    return name


def number_cfg(label=None, fmt="%,d"):
    return st.column_config.NumberColumn(label=label, format=fmt)


def percent_cfg(label=None, fmt="%.1f%%"):
    return st.column_config.NumberColumn(label=label, format=fmt)


def download_button_df(df: pd.DataFrame, label: str, filename: str):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(label=label, data=csv, file_name=filename, mime="text/csv")

# DatetimeIndex æœ€è¿‘å‚ä½ç½®ï¼ˆå …ç‰¢ç‰ˆï¼‰
def _nearest_pos_by_ns(idx: pd.DatetimeIndex, t0: pd.Timestamp) -> int:
    if not isinstance(idx, pd.DatetimeIndex):
        idx = pd.DatetimeIndex(idx)
    if idx.tz is None:
        idx = idx.tz_localize(TZ)
    if t0.tzinfo is None:
        t0 = t0.tz_localize(TZ)
    idx_ns = idx.view("int64")
    t0_ns = int(pd.Timestamp(t0).value)
    dist = np.abs(idx_ns - t0_ns)
    return int(dist.argmin())

# è¿‘å‚ãƒãƒ¼ã¸ã‚¹ãƒŠãƒƒãƒ—ï¼ˆè²·å»º/å£²å»º/å£²åŸ‹/è²·åŸ‹ï¼‰
def align_trades_to_ohlc(ohlc: pd.DataFrame, trades: pd.DataFrame, max_gap_min=6):
    if ohlc is None or ohlc.empty or trades is None or trades.empty:
        return pd.DataFrame(columns=["time","price","side","qty","label4"])

    tdf = trades.copy()
    tdf["ç´„å®šæ—¥æ™‚"] = _to_jst_series(tdf["ç´„å®šæ—¥æ™‚"] if "ç´„å®šæ—¥æ™‚" in tdf.columns else None, tdf.index)

    price_col = next((c for c in ["ç´„å®šå˜ä¾¡(å††)","ç´„å®šå˜ä¾¡ï¼ˆå††ï¼‰","ç´„å®šä¾¡æ ¼","ä¾¡æ ¼","ç´„å®šå˜ä¾¡"] if c in tdf.columns), None)
    qty_col   = next((c for c in ["ç´„å®šæ•°é‡(æ ª/å£)","ç´„å®šæ•°é‡","å‡ºæ¥æ•°é‡","æ•°é‡","æ ªæ•°","å‡ºæ¥é«˜","å£æ•°"] if c in tdf.columns), None)
    side_col  = next((c for c in ["å£²è²·","å£²è²·åŒºåˆ†","å£²è²·ç¨®åˆ¥","Side","å–å¼•"] if c in tdf.columns), None)
    if price_col is None:
        for c in tdf.columns:
            if re.search(r"(ç´„å®š)?.*(å˜ä¾¡|ä¾¡æ ¼)", str(c)):
                price_col = c; break
    if qty_col is None:
        for c in tdf.columns:
            if any(k in str(c) for k in ["æ•°é‡","æ ªæ•°","å£æ•°","å‡ºæ¥é«˜"]):
                qty_col = c; break

    tdf["price"] = to_numeric_jp(tdf[price_col]) if price_col else np.nan
    tdf["qty"]   = to_numeric_jp(tdf[qty_col])   if qty_col else np.nan
    tdf["side"]  = tdf[side_col].astype(str) if side_col else ""

    def classify_side4(s: str) -> str | None:
        s = str(s)
        if "è²·å»º" in s: return "è²·å»º"
        if "å£²å»º" in s: return "å£²å»º"
        if "å£²åŸ‹" in s: return "å£²åŸ‹"
        if "è²·åŸ‹" in s: return "è²·åŸ‹"
        if ("è²·" in s and ("æ–°è¦" in s or "å»º" in s)) or re.search(r"\bBUY\b.*\b(OPEN|NEW)\b", s, re.I): return "è²·å»º"
        if ("å£²" in s and ("æ–°è¦" in s or "å»º" in s)) or re.search(r"\bSELL\b.*\b(OPEN|NEW)\b", s, re.I): return "å£²å»º"
        if ("å£²" in s and ("è¿”æ¸ˆ" in s or "æ±ºæ¸ˆ" in s)) or re.search(r"\bSELL\b.*\b(CLOSE)\b", s, re.I): return "å£²åŸ‹"
        if ("è²·" in s and ("è¿”æ¸ˆ" in s or "æ±ºæ¸ˆ" in s)) or re.search(r"\bBUY\b.*\b(CLOSE|COVER)\b", s, re.I): return "è²·åŸ‹"
        return None

    tdf["label4"] = tdf["side"].map(classify_side4)

    odf = ohlc.copy()
    tt = _to_jst_series(odf["time"], odf.index)
    odf = odf.set_index(tt).sort_index()

    out_rows = []
    for _, row in tdf.iterrows():
        t0 = row["ç´„å®šæ—¥æ™‚"]
        if pd.isna(t0) or not row.get("label4"):
            continue
        lo = t0 - pd.Timedelta(minutes=max_gap_min)
        hi = t0 + pd.Timedelta(minutes=max_gap_min)
        window = odf.loc[lo:hi]
        if window.empty:
            continue
        pos = _nearest_pos_by_ns(window.index, t0)
        near_time = window.index[pos]
        price_on_bar = window.loc[near_time, "close"]
        out_rows.append({
            "time": near_time, "price": price_on_bar,
            "side": row["side"], "qty": row["qty"], "label4": row["label4"]
        })
    return pd.DataFrame(out_rows)

# =============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
# =============================
st.sidebar.header("ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
enc = st.sidebar.selectbox("æ–‡å­—ã‚³ãƒ¼ãƒ‰", ["utf-8-sig", "cp932", "utf-8", "ISO-2022-JP", "latin-1"], index=0)

ohlc_files = st.sidebar.file_uploader("3åˆ†è¶³ OHLC CSVï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)
fill_files = st.sidebar.file_uploader("ç´„å®šå±¥æ­´ CSVï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)
realized_files = st.sidebar.file_uploader("å®Ÿç¾æç›Š CSVï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv"], accept_multiple_files=True)

ma1 = st.sidebar.number_input("MA1 ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", min_value=1, max_value=200, value=5)
ma2 = st.sidebar.number_input("MA2 ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", min_value=1, max_value=400, value=20)
ma3 = st.sidebar.number_input("MA3 ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", min_value=1, max_value=800, value=60)

# =============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =============================
# 3åˆ†è¶³
ohlc_map: dict[str, pd.DataFrame] = {}
if ohlc_files:
    for f in ohlc_files:
        try:
            df = read_csv_safely(f, encoding=enc)
            # åˆ—åæ¨™æº–åŒ–
            cols = {c.lower(): c for c in df.columns}
            def pick(*names):
                for n in names:
                    if n in cols:
                        return cols[n]
                return None
            c_time = pick("time", "æ—¥æ™‚", "date", "datetime")
            c_open = pick("open", "å§‹å€¤")
            c_high = pick("high", "é«˜å€¤")
            c_low  = pick("low",  "å®‰å€¤")
            c_close= pick("close","çµ‚å€¤")
            c_vol  = pick("volume","å‡ºæ¥é«˜","vol")
            if not all([c_time, c_open, c_high, c_low, c_close]):
                st.warning(f"{f.name}: å¿…é ˆåˆ—(time/open/high/low/close)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            out = pd.DataFrame({
                "time": ensure_jst(df[c_time]),
                "open": to_numeric_jp(df[c_open]),
                "high": to_numeric_jp(df[c_high]),
                "low":  to_numeric_jp(df[c_low]),
                "close":to_numeric_jp(df[c_close]),
            })
            if c_vol:
                out[c_vol] = to_numeric_jp(df[c_vol])
            out = compute_vwap_by_day(out)
            out = add_mas(out, w1=ma1, w2=ma2, w3=ma3)
            ohlc_map[f.name] = out
        except Exception as e:
            st.error(f"OHLCèª­è¾¼å¤±æ•—: {f.name}: {e}")

# ç´„å®šå±¥æ­´
yakujyou_all = pd.DataFrame()
if fill_files:
    frames = []
    for f in fill_files:
        try:
            d = read_csv_safely(f, encoding=enc)
            d["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(d)
            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„åã®æ¨™æº–åŒ–
            code_col = next((c for c in ["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰","ã‚³ãƒ¼ãƒ‰","code","symbol"] if c in d.columns), None)
            name_col = next((c for c in ["éŠ˜æŸ„å","åç§°","name"] if c in d.columns), None)
            if code_col: d["code_key"] = d[code_col].astype(str).str.upper()
            if name_col: d["name_key"] = d[name_col].astype(str)
            frames.append(d)
        except Exception as e:
            st.error(f"ç´„å®šå±¥æ­´èª­è¾¼å¤±æ•—: {f.name}: {e}")
    if frames:
        yakujyou_all = pd.concat(frames, ignore_index=True)

# å®Ÿç¾æç›Š
realized_all = pd.DataFrame()
if realized_files:
    frames = []
    for f in realized_files:
        try:
            d = read_csv_safely(f, encoding=enc)
            d["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(d)
            # æç›Šåˆ—ã‚’æ¨å®š
            pl_col = next((c for c in [
                "å®Ÿç¾æç›Šï¼ˆå††ï¼‰","å®Ÿç¾æç›Š(å††)","å®Ÿç¾æç›Š","æç›Š","æç›Š[å††]","æç›Š(å††)","æç›Šï¼ˆå††ï¼‰",
                "Realized P&L","P&L","PL","Profit"
            ] if c in d.columns), None)
            if pl_col is None:
                # æ­£è¦è¡¨ç¾ã§ "æç›Š" ã‚’å«ã‚€åˆ—ã®ã†ã¡ã€æ•°å€¤åŒ–ã§ããã†ãªã‚‚ã®
                for c in d.columns:
                    if re.search(r"æç›Š|P&L|PL|Profit", str(c), re.I):
                        pl_col = c; break
            if pl_col is not None:
                d["å®Ÿç¾æç›Š[å††]"] = to_numeric_jp(d[pl_col])
            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„åã®æ¨™æº–åŒ–
            code_col = next((c for c in ["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰","ã‚³ãƒ¼ãƒ‰","code","symbol"] if c in d.columns), None)
            name_col = next((c for c in ["éŠ˜æŸ„å","åç§°","name"] if c in d.columns), None)
            if code_col: d["code_key"] = d[code_col].astype(str).str.upper()
            if name_col: d["name_key"] = d[name_col].astype(str)
            frames.append(d)
        except Exception as e:
            st.error(f"å®Ÿç¾æç›Šèª­è¾¼å¤±æ•—: {f.name}: {e}")
    if frames:
        realized_all = pd.concat(frames, ignore_index=True)

# éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰â†’åç§°ã®ãƒãƒƒãƒ—
CODE_TO_NAME: dict[str, str] = {}
for df in [yakujyou_all, realized_all]:
    if not df.empty and "code_key" in df.columns and "name_key" in df.columns:
        pairs = df[["code_key","name_key"]].dropna().drop_duplicates()
        for _, r in pairs.iterrows():
            CODE_TO_NAME[str(r["code_key"]).upper()] = str(r["name_key"]) if pd.notna(r["name_key"]) else CODE_TO_NAME.get(str(r["code_key"]).upper(), None)

# =============================
# ã‚¿ãƒ–æ§‹æˆ
# =============================
st.title("ğŸ“Š ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

TAB_NAMES = ["é›†è¨ˆï¼ˆæœŸé–“åˆ¥ï¼‰", "é›†è¨ˆï¼ˆæ™‚é–“åˆ¥ï¼‰", "ç´¯è¨ˆæç›Š", "å€‹åˆ¥éŠ˜æŸ„", "3åˆ†è¶³ IN/OUT + æŒ‡æ¨™"]

tab1, tab2, tab3, tab4, tab5 = st.tabs(TAB_NAMES)

# -----------------------------
# 1) é›†è¨ˆï¼ˆæœŸé–“åˆ¥ï¼‰
# -----------------------------
with tab1:
    st.subheader("é›†è¨ˆï¼ˆæœŸé–“åˆ¥ï¼‰")
    if realized_all.empty or "å®Ÿç¾æç›Š[å††]" not in realized_all.columns:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆæç›Šåˆ—ãŒå¿…è¦ï¼‰")
    else:
        r = realized_all.copy()
        r["dt"] = pick_dt_with_optional_time(r)
        r["æ—¥"] = ensure_jst(r["dt"]).dt.date
        r["é€±"] = ensure_jst(r["dt"]).dt.to_period("W-MON").apply(lambda p: p.start_time.date())
        r["æœˆ"] = ensure_jst(r["dt"]).dt.to_period("M").apply(lambda p: p.start_time.date())
        r["å¹´"] = ensure_jst(r["dt"]).dt.to_period("Y").apply(lambda p: p.start_time.date())

        for label, col in [("æ—¥åˆ¥","æ—¥"),("é€±åˆ¥","é€±"),("æœˆåˆ¥","æœˆ"),("å¹´åˆ¥","å¹´")]:
            g = r.groupby(col, as_index=False)["å®Ÿç¾æç›Š[å††]"].sum().sort_values(col)
            g_disp = g.copy()
            g_disp["æ—¥ä»˜"] = pd.to_datetime(g_disp[col]).dt.strftime("%Y-%m-%d")

            st.write(f"**{label}**")
            st.dataframe(
                g_disp[["æ—¥ä»˜","å®Ÿç¾æç›Š[å††]"]],
                use_container_width=True, hide_index=True,
                column_config={
                    "å®Ÿç¾æç›Š[å††]": number_cfg("å®Ÿç¾æç›Š[å††]", fmt="%,d"),
                },
            )
            fig_bar = go.Figure([go.Bar(x=g_disp["æ—¥ä»˜"], y=g["å®Ÿç¾æç›Š[å††]"], name=f"{label} å®Ÿç¾æç›Š")])
            fig_bar.update_layout(margin=dict(l=10,r=10,t=20,b=10), height=320, xaxis_title="æ—¥ä»˜", yaxis_title="å®Ÿç¾æç›Š[å††]")
            st.plotly_chart(fig_bar, use_container_width=True)
            download_button_df(g[[col, "å®Ÿç¾æç›Š[å††]"]].rename(columns={col: "date"}), f"â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{label}ï¼‰", f"agg_{col}.csv")

# -----------------------------
# 2) é›†è¨ˆï¼ˆæ™‚é–“åˆ¥ï¼‰
# -----------------------------
with tab2:
    st.subheader("é›†è¨ˆï¼ˆæ™‚é–“åˆ¥ï¼‰")
    if realized_all.empty or "å®Ÿç¾æç›Š[å††]" not in realized_all.columns:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆæç›Šåˆ—ãŒå¿…è¦ï¼‰")
    else:
        df = realized_all.copy()
        dt = pick_dt_with_optional_time(df)
        df = df.assign(ç´„å®šæ—¥æ™‚=dt)
        # æ™‚åˆ»ãŒNaTã®ã‚‚ã®ã¯é™¤å¤–
        df = df[df["ç´„å®šæ—¥æ™‚"].notna()].copy()
        tl = ensure_jst(df["ç´„å®šæ—¥æ™‚"]).dt.time
        mask_mkt = (tl >= time(9,0)) & (tl <= time(15,30))
        df = df[mask_mkt]
        if df.empty:
            st.info("å¸‚å ´æ™‚é–“å†…ã®æ™‚åˆ»ä»˜ããƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            df["hour_x"] = ensure_jst(df["ç´„å®šæ—¥æ™‚"]).dt.floor("h")
            by = df.groupby("hour_x").agg(
                åæ”¯=("å®Ÿç¾æç›Š[å††]", "sum"),
                å–å¼•å›æ•°=("å®Ÿç¾æç›Š[å††]", "count"),
                å‹ç‡=("å®Ÿç¾æç›Š[å††]", lambda s: np.nan if len(s)==0 else (s>0).mean()),
                å¹³å‡æç›Š=("å®Ÿç¾æç›Š[å††]", lambda s: s.mean() if len(s)>0 else np.nan)
            ).reset_index()
            # è¡¨ç¤ºï¼ˆæ•°å€¤ã¯ dtype ã®ã¾ã¾ï¼‰
            df_hour = by.copy()
            df_hour["æ™‚é–“"] = ensure_jst(df_hour["hour_x"]).dt.strftime("%H:%M")
            df_hour["å‹ç‡(%)"] = (df_hour["å‹ç‡"].fillna(0)*100).round(1)

            st.dataframe(
                df_hour[["æ™‚é–“","åæ”¯","å–å¼•å›æ•°","å‹ç‡(%)","å¹³å‡æç›Š"]],
                use_container_width=True, hide_index=True,
                column_config={
                    "åæ”¯": number_cfg("åæ”¯", fmt="%,d"),
                    "å–å¼•å›æ•°": number_cfg("å–å¼•å›æ•°", fmt="%,d"),
                    "å¹³å‡æç›Š": number_cfg("å¹³å‡æç›Š", fmt="%,d"),
                    "å‹ç‡(%)": percent_cfg("å‹ç‡(%)", fmt="%.1f%%"),
                }
            )
            download_button_df(by, "â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ™‚é–“åˆ¥ï¼‰", "hourly_stats.csv")

            # ã‚°ãƒ©ãƒ•ï¼šæ™‚é–“é †ã«
            fig1 = go.Figure([go.Bar(x=df_hour["æ™‚é–“"], y=by["åæ”¯"], name="åæ”¯")])
            fig1.update_layout(height=300, margin=dict(l=10,r=10,t=20,b=10), xaxis_title="æ™‚é–“", yaxis_title="åæ”¯")
            st.plotly_chart(fig1, use_container_width=True)

            fig2 = go.Figure([go.Scatter(x=df_hour["æ™‚é–“"], y=df_hour["å‹ç‡(%)"], mode="lines+markers", name="å‹ç‡")])
            fig2.update_layout(height=300, margin=dict(l=10,r=10,t=20,b=10), xaxis_title="æ™‚é–“", yaxis_title="å‹ç‡(%)")
            st.plotly_chart(fig2, use_container_width=True)

# -----------------------------
# 3) ç´¯è¨ˆæç›Š
# -----------------------------
with tab3:
    st.subheader("ç´¯è¨ˆæç›Š")
    if realized_all.empty or "å®Ÿç¾æç›Š[å††]" not in realized_all.columns:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆæç›Šåˆ—ãŒå¿…è¦ï¼‰")
    else:
        r = realized_all.copy()
        r["dt"] = pick_dt_with_optional_time(r)
        r = r[r["dt"].notna()].copy()
        r["æ—¥"] = ensure_jst(r["dt"]).dt.date
        seq = r.groupby("æ—¥", as_index=False)["å®Ÿç¾æç›Š[å††]"].sum().sort_values("æ—¥")
        seq["ç´¯è¨ˆ"] = seq["å®Ÿç¾æç›Š[å††]"].cumsum()
        seq_disp = seq.copy()
        seq_disp["æ—¥ä»˜"] = pd.to_datetime(seq_disp["æ—¥"]).dt.strftime("%Y-%m-%d")
        st.dataframe(
            seq_disp[["æ—¥ä»˜","å®Ÿç¾æç›Š[å††]","ç´¯è¨ˆ"]],
            use_container_width=True, hide_index=True,
            column_config={
                "å®Ÿç¾æç›Š[å††]": number_cfg("å®Ÿç¾æç›Š[å††]", fmt="%,d"),
                "ç´¯è¨ˆ": number_cfg("ç´¯è¨ˆ", fmt="%,d"),
            }
        )
        download_button_df(seq.rename(columns={"æ—¥":"date"}), "â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´¯è¨ˆãƒ»æ—¥æ¬¡ï¼‰", "cumulative_daily_pl.csv")

        fig = go.Figure([
            go.Bar(x=seq_disp["æ—¥ä»˜"], y=seq["å®Ÿç¾æç›Š[å††]"], name="å®Ÿç¾æç›Š[å††]"),
            go.Scatter(x=seq_disp["æ—¥ä»˜"], y=seq["ç´¯è¨ˆ"], name="ç´¯è¨ˆ", mode="lines")
        ])
        fig.update_layout(height=360, margin=dict(l=10,r=10,t=20,b=10), xaxis_title="æ—¥ä»˜", yaxis_title="é‡‘é¡[å††]")
        st.plotly_chart(fig, use_container_width=True)

# -----------------------------
# 4) å€‹åˆ¥éŠ˜æŸ„
# -----------------------------
with tab4:
    st.subheader("å€‹åˆ¥éŠ˜æŸ„")
    if realized_all.empty or "å®Ÿç¾æç›Š[å††]" not in realized_all.columns:
        st.info("å®Ÿç¾æç›Šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆæç›Šåˆ—ãŒå¿…è¦ï¼‰")
    else:
        r = realized_all.copy()
        # ã‚³ãƒ¼ãƒ‰ãƒ»åç§°ã®æ¨å®š
        if "code_key" not in r.columns:
            c = next((c for c in ["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰","ã‚³ãƒ¼ãƒ‰","code","symbol"] if c in r.columns), None)
            if c: r["code_key"] = r[c].astype(str).str.upper()
        if "name_key" not in r.columns:
            c = next((c for c in ["éŠ˜æŸ„å","åç§°","name"] if c in r.columns), None)
            if c: r["name_key"] = r[c].astype(str)

        if "code_key" not in r.columns:
            st.info("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            agg = r.groupby("code_key").agg(**{
                "å®Ÿç¾æç›Šåˆè¨ˆ": ("å®Ÿç¾æç›Š[å††]", "sum"),
                "å–å¼•å›æ•°": ("å®Ÿç¾æç›Š[å††]", "count"),
                "1å›å¹³å‡æç›Š": ("å®Ÿç¾æç›Š[å††]", "mean"),
                "éŠ˜æŸ„å": ("name_key", lambda s: s.dropna().iloc[0] if s.dropna().size>0 else ""),
            }).reset_index().rename(columns={"code_key":"éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰"})

            st.dataframe(
                agg[["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰","éŠ˜æŸ„å","å®Ÿç¾æç›Šåˆè¨ˆ","å–å¼•å›æ•°","1å›å¹³å‡æç›Š"]],
                use_container_width=True, hide_index=True,
                column_config={
                    "å®Ÿç¾æç›Šåˆè¨ˆ": number_cfg("å®Ÿç¾æç›Šåˆè¨ˆ", fmt="%,d"),
                    "å–å¼•å›æ•°": number_cfg("å–å¼•å›æ•°", fmt="%,d"),
                    "1å›å¹³å‡æç›Š": number_cfg("1å›å¹³å‡æç›Š", fmt="%,d"),
                }
            )
            download_button_df(agg, "â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå€‹åˆ¥éŠ˜æŸ„ï¼‰", "per_symbol_stats.csv")

# -----------------------------
# 5) 3åˆ†è¶³ IN/OUT + æŒ‡æ¨™ï¼ˆå…ˆã«æ—¥ä»˜é¸æŠ â†’ ãã®æ—¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ã®ã¿ï¼‰
# -----------------------------

def make_candle_with_indicators(df: pd.DataFrame, title="", height=560, x_range=None):
    fig = go.Figure()
    fig.add_trace(go.Candlestick(
        x=df["time"], open=df["open"], high=df["high"], low=df["low"], close=df["close"],
        name="OHLC", showlegend=False
    ))
    if "VWAP" in df.columns and df["VWAP"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["VWAP"], name="VWAP", mode="lines",
                                 line=dict(color=COLOR_VWAP, width=1.3)))
    if "MA1" in df.columns and df["MA1"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA1"], name="MA1", mode="lines",
                                 line=dict(color=COLOR_MA1, width=1.3)))
    if "MA2" in df.columns and df["MA2"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA2"], name="MA2", mode="lines",
                                 line=dict(color=COLOR_MA2, width=1.3)))
    if "MA3" in df.columns and df["MA3"].notna().any():
        fig.add_trace(go.Scatter(x=df["time"], y=df["MA3"], name="MA3", mode="lines",
                                 line=dict(color=COLOR_MA3, width=1.3)))

    fig.update_layout(
        title=title, height=height, margin=dict(l=10, r=10, t=40, b=10),
        xaxis_rangeslider_visible=False,
        xaxis=dict(showgrid=False, range=x_range),
        yaxis=dict(showgrid=True)
    )
    return fig

with tab5:
    st.subheader("3åˆ†è¶³ IN/OUT + æŒ‡æ¨™ï¼ˆVWAP/MA1/MA2/MA3ï¼‰")
    if not ohlc_map:
        st.info("3åˆ†è¶³OHLCãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        dmin, dmax = ohlc_global_date_range(ohlc_map)
        if dmin is None or dmax is None:
            st.info("æœ‰åŠ¹ãªæ—¥æ™‚åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            today_jst = datetime.now(pd.Timestamp.now(tz=TZ).tz).date()
            default_day = today_jst
            if dmin and default_day < dmin: default_day = dmin
            if dmax and default_day > dmax: default_day = dmax

            c1, c2, c3 = st.columns([2,2,1])
            with c1:
                sel_date = st.date_input("è¡¨ç¤ºæ—¥ã‚’é¸æŠ", value=default_day, min_value=dmin, max_value=dmax)
            with c2:
                enlarge = st.toggle("ğŸ” æ‹¡å¤§è¡¨ç¤º", value=False, help="ãƒã‚§ãƒƒã‚¯ã§ãƒãƒ£ãƒ¼ãƒˆã‚’å¤§ããã—ã¾ã™")
            with c3:
                ht = LARGE_CHART_HEIGHT if enlarge else MAIN_CHART_HEIGHT

            # æ™‚é–“ãƒ¬ãƒ³ã‚¸å›ºå®š 9:00ã€œ15:30
            t0 = pd.Timestamp(f"{sel_date} 09:00", tz=TZ)
            t1 = pd.Timestamp(f"{sel_date} 15:30", tz=TZ)
            x_range = [t0, t1]

            # é¸æŠæ—¥ã®ç´„å®šè¡¨ï¼ˆå…¨éŠ˜æŸ„ï¼‰
            st.markdown("#### ç´„å®šè¡¨ï¼ˆé¸æŠæ—¥ãƒ»å…¨éŠ˜æŸ„ï¼‰")
            if yakujyou_all is None or yakujyou_all.empty:
                st.info("ç´„å®šå±¥æ­´ãŒæœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã™ã€‚")
            else:
                yak_day_all = yakujyou_all.copy()
                yak_day_all["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(yak_day_all)
                yak_day_all = yak_day_all[yak_day_all["ç´„å®šæ—¥æ™‚"].notna()]
                yak_day_all = yak_day_all[(yak_day_all["ç´„å®šæ—¥æ™‚"]>=t0) & (yak_day_all["ç´„å®šæ—¥æ™‚"]<=t1)].copy()
                if yak_day_all.empty:
                    st.info(f"{sel_date} ã®å¸‚å ´æ™‚é–“å†…ã«ç´„å®šã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    price_col = next((c for c in ["ç´„å®šå˜ä¾¡(å††)","ç´„å®šå˜ä¾¡ï¼ˆå††ï¼‰","ç´„å®šä¾¡æ ¼","ä¾¡æ ¼","ç´„å®šå˜ä¾¡"] if c in yak_day_all.columns), None)
                    if price_col is None:
                        for c in yak_day_all.columns:
                            if re.search(r"(ç´„å®š)?.*(å˜ä¾¡|ä¾¡æ ¼)", str(c)):
                                price_col = c; break
                    qty_col = next((c for c in ["ç´„å®šæ•°é‡(æ ª/å£)","ç´„å®šæ•°é‡","å‡ºæ¥æ•°é‡","æ•°é‡","æ ªæ•°","å‡ºæ¥é«˜","å£æ•°"] if c in yak_day_all.columns), None)
                    if qty_col is None:
                        for c in yak_day_all.columns:
                            if any(k in str(c) for k in ["æ•°é‡","æ ªæ•°","å£æ•°","å‡ºæ¥é«˜"]):
                                qty_col = c; break
                    side_col  = next((c for c in ["å£²è²·","å£²è²·åŒºåˆ†","å£²è²·ç¨®åˆ¥","Side","å–å¼•"] if c in yak_day_all.columns), None)

                    disp = pd.DataFrame({
                        "æ™‚åˆ»": ensure_jst(yak_day_all["ç´„å®šæ—¥æ™‚"]).dt.strftime("%H:%M:%S"),
                        "éŠ˜æŸ„å": yak_day_all.get("name_key", pd.Series([""]*len(yak_day_all))),
                        "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰": yak_day_all.get("code_key", pd.Series([""]*len(yak_day_all))),
                        "å£²è²·": yak_day_all[side_col] if side_col else "",
                        "ä¾¡æ ¼": to_numeric_jp(yak_day_all[price_col]) if price_col else np.nan,
                        "æ•°é‡": to_numeric_jp(yak_day_all[qty_col]) if qty_col else np.nan,
                    }).sort_values("æ™‚åˆ»")

                    st.dataframe(
                        disp,
                        use_container_width=True, hide_index=True,
                        column_config={
                            "ä¾¡æ ¼": number_cfg("ä¾¡æ ¼", fmt="%,d"),
                            "æ•°é‡": number_cfg("æ•°é‡", fmt="%,d"),
                        }
                    )
                    download_button_df(disp, f"â¬‡ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„å®šè¡¨ {sel_date}ï¼‰", f"fills_{sel_date}.csv")

            # å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ã®ã¿é¸æŠå¯èƒ½ã«
            keys_that_day = []
            for k, df in ohlc_map.items():
                if df is None or df.empty:
                    continue
                vw = df[(df["time"]>=t0) & (df["time"]<=t1)]
                if not vw.empty:
                    keys_that_day.append(k)

            if not keys_that_day:
                st.info("é¸æŠæ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ¥ã®æ—¥ä»˜ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
            else:
                options = sorted(keys_that_day)
                def _fmt_label(k):
                    nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                    return f"{k}ï¼ˆ{nm}ï¼‰" if nm else k
                sel_key = st.selectbox("éŠ˜æŸ„ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã‚’é¸æŠ", options=options, index=0, format_func=_fmt_label)
                sel_name = guess_name_for_ohlc_key(sel_key, CODE_TO_NAME)
                if sel_name:
                    st.caption(f"æƒ³å®šéŠ˜æŸ„å: **{sel_name}**")

                view = ohlc_map[sel_key]
                view = view[(view["time"]>=t0) & (view["time"]<=t1)].copy()
                if view.empty:
                    st.info(f"{sel_key}ï¼š{sel_date} ã®3åˆ†è¶³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    # è©²å½“ã‚³ãƒ¼ãƒ‰ã®ç´„å®šã‚’å½“æ—¥æŠ½å‡º
                    yak = yakujyou_all.copy()
                    if "code_key" in yak.columns:
                        this_code = extract_code_from_ohlc_key(sel_key) or ""
                        if this_code:
                            yak = yak[yak["code_key"].astype(str).str.upper()==this_code.upper()]
                    yak = yak.copy()
                    yak["ç´„å®šæ—¥æ™‚"] = pick_dt_with_optional_time(yak)
                    yak = yak[yak["ç´„å®šæ—¥æ™‚"].notna()]
                    yak = yak[(yak["ç´„å®šæ—¥æ™‚"]>=t0) & (yak["ç´„å®šæ—¥æ™‚"]<=t1)]

                    trades = align_trades_to_ohlc(view, yak, max_gap_min=6) if not yak.empty else pd.DataFrame(columns=["time","price","side","qty","label4"])

                    title_text = f"{sel_name} [{sel_key}]" if sel_name else sel_key
                    fig = make_candle_with_indicators(view, title=title_text, height=ht, x_range=x_range)

                    marker_styles = {
                        "è²·å»º": dict(symbol="triangle-up",        size=11, color="#2ca02c", line=dict(width=1.2)),
                        "å£²å»º": dict(symbol="triangle-down",      size=11, color="#d62728", line=dict(width=1.2)),
                        "å£²åŸ‹": dict(symbol="triangle-down-open", size=12, color="#9467bd", line=dict(width=1.4)),
                        "è²·åŸ‹": dict(symbol="triangle-up-open",   size=12, color="#1f77b4", line=dict(width=1.4)),
                    }
                    if not trades.empty:
                        for label, mk in marker_styles.items():
                            sub = trades[trades["label4"] == label]
                            if not sub.empty:
                                fig.add_trace(go.Scatter(
                                    x=sub["time"], y=sub["price"], mode="markers",
                                    name=label, marker=mk,
                                    hovertemplate=f"{label}<br>%{{x|%H:%M}}<br>Â¥%{{y:.0f}}<extra></extra>"
                                ))

                    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": True})

                # ä¸‹æ®µï¼šæ—¥çµŒå…ˆç‰© / æ—¥çµŒå¹³å‡ï¼ˆãã®æ—¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚‚ã®ã®ã¿ãƒ»æ™‚é–“å›ºå®šï¼‰
                fut_keys = [k for k in keys_that_day if ("NK2251" in k or "OSE_NK2251" in k)]
                idx_keys = [k for k in keys_that_day if ("NI225" in k or "TVC_NI225" in k)]

                st.markdown("#### æ—¥çµŒå…ˆç‰©ï¼ˆNK225miniç­‰ï¼‰")
                if fut_keys:
                    k = fut_keys[0]
                    df = ohlc_map.get(k)
                    vw = df[(df["time"]>=t0) & (df["time"]<=t1)].copy()
                    if not vw.empty:
                        nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                        ttl = f"{nm} [{k}]" if nm else k
                        figx = make_candle_with_indicators(vw, title=ttl, height=ht, x_range=x_range)
                        st.plotly_chart(figx, use_container_width=True, config={"displayModeBar": True})
                    else:
                        st.info(f"{k}ï¼š{sel_date} ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
                else:
                    st.info("æ—¥çµŒå…ˆç‰©ï¼ˆ`OSE_NK2251!` ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

                st.markdown("#### æ—¥çµŒå¹³å‡")
                if idx_keys:
                    k = idx_keys[0]
                    df = ohlc_map.get(k)
                    vw = df[(df["time"]>=t0) & (df["time"]<=t1)].copy()
                    if not vw.empty:
                        nm = guess_name_for_ohlc_key(k, CODE_TO_NAME)
                        ttl = f"{nm} [{k}]" if nm else k
                        figx = make_candle_with_indicators(vw, title=ttl, height=ht, x_range=x_range)
                        st.plotly_chart(figx, use_container_width=True, config={"displayModeBar": True})
                    else:
                        st.info(f"{k}ï¼š{sel_date} ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
                else:
                    st.info("æ—¥çµŒå¹³å‡ï¼ˆ`TVC_NI225` ãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
